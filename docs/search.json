[
  {
    "objectID": "06-scripts.html",
    "href": "06-scripts.html",
    "title": "Scripts",
    "section": "",
    "text": "So far in this course we have learned how to work interactively on the command line to analyse data. This section will introduce the idea of bash shell scripting. We will also introduce the concept of reproducible data analysis, and will show how using scripts to analyse data can facilitate this."
  },
  {
    "objectID": "06-scripts.html#shell-scripts-in-bash",
    "href": "06-scripts.html#shell-scripts-in-bash",
    "title": "Scripts",
    "section": "Shell scripts in bash",
    "text": "Shell scripts in bash\n\n\n Key points\n\n\nA shell script is a text file containing multiple commands, which can then be run from the command line as a single command\n\n\n\nWriting and running your own scripts\nIn its most basic form, a shell script is simply a text file containing a list of commands that is run in sequence from top to bottom. This kind of script can be run by providing it as an argument to the bash command, as in the following example:\n\n[USERNAME]@aabn:~$ date\nThu 12 Nov 14:21:16 GMT 2020\n[USERNAME]@aabn:~$ echo hello\nhello\n[USERNAME]@aabn:~$ ls /home2/swebb/training/Intro_to_Linux/genomes/mouse/\nGRCm38  mm10  mm9  UCSC\n[USERNAME]@aabn:~$ echo date > my_script.sh\n[USERNAME]@aabn:~$ echo 'echo hello' >> my_script.sh\n[USERNAME]@aabn:~$ echo 'ls /home2/swebb/training/Intro_to_Linux/genomes/mouse/' >> my_script.sh\n[USERNAME]@aabn:~$ cat my_script.sh\ndate\necho hello\nls /home2/swebb/training/Intro_to_Linux/genomes/mouse/\n[USERNAME]@aabn:~$ bash my_script.sh\nThu 12 Nov 14:26:29 GMT 2020\nhello\nGRCm38  mm10  mm9  UCSC\n[USERNAME]@aabn:~$\n\nIt is also possible to create a script that can be run as a standalone program rather than as an argument to bash. This involves two steps:\n\nAdd the line #!/bin/bash (known as a shebang line) as the first line of the file using a text editor\nUse the chmod command to make the file executable\n\nchmod a+x my_script.sh will change the permissions on the script so that any user can run it\n\n\nOnce these steps have been followed, it will be possible to execute the script using its path:\n\n[USERNAME]@aabn:~$ cat my_script.sh\n#!/bin/bash\ndate\necho hello\nls /home2/swebb/training/Intro_to_Linux/genomes/mouse/\n[USERNAME]@aabn:~$ ls -l ./my_script.sh\n-rwxrwxr-x 1 [USERNAME] [USERNAME] 0 Nov 13 21:40 my_script.sh\n[USERNAME]@aabn:~$ ./my_script.sh\nThu 12 Nov 14:26:29 GMT 2020\nhello\nGRCm38  mm10  mm9  UCSC\n[USERNAME]@aabn:~$ \n\nNote: If you want to be able to run your script just by typing its name, you need to move it to a directory that is included in the $PATH environment variable.\n\nTo check which folders are listed in $PATH, you can type echo $PATH\nTo add a directory to $PATH permanently, add the line export PATH=[YOUR DIRECTORY]:$PATH to the end of the ~/.bashrc file, then run the command source ~/.bashrc\nIf you run a program from a directory in $PATH, it can be useful to check the full path to that program to make sure you’re not inadvertently running another program with the same name. You can do this by using the which command.\n\n\n\nEditing scripts\nYou can edit your scripts using a text editor such as emacs or vim.\n\nemacs opens emacs\n\nyou can then take the tutorial by typing Ctrl+h t\n\nvim opens vim\n\nyou can take a tutorial by running the vimtutor command at the bash prompt"
  },
  {
    "objectID": "06-scripts.html#reproducible-data-analysis-with-scripts",
    "href": "06-scripts.html#reproducible-data-analysis-with-scripts",
    "title": "Scripts",
    "section": "Reproducible data analysis with scripts",
    "text": "Reproducible data analysis with scripts\n\n\n Key points\n\n\nData analysis should be reproducible\n\nYou should be able to recreate all of the steps in your analysis\nOther researchers should also be able to recreate your analysis to verify your results\n\nThe bash shell makes it easy to analyse data interactively. However, if data is analysed this way it can be difficult to keep track of exactly which steps were taken to produce a given result\nThis problem can be solved by creating a script that contains all of the commands needed to produce the results\n\nYou and other researchers can then recreate your analysis by running the script\n\nThis section presents a bash script that replicates the case study performed in the previous section\n\n\nIn the previous section we showed how to perform a simple analysis of some RNA-Seq data from scratch. In order turn this into a reproducible analysis workflow, it is necessary to put all of the commands that make up the analysis into a script.\n\nCreating a simple data analysis script\nThe simplest way to create a script is to put all of the commands that made up the analysis into a file in the order in which they were run, creating a file that looks like this:\n\nmkdir analysis\ncd analysis\nmkdir 00_source_data\ncd 00_source_data\nln -s ../../bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq\ncd ..\ntree\nmkdir 01_star_index\ncd 01_star_index\nln -s ../../bioinformatics_on_the_command_line_files/yeast_genome.fasta\nnice STAR --runThreadN 5 --runMode genomeGenerate --genomeDir . --genomeFastaFiles ./yeast_genome.fasta --genomeSAindexNbases 10\ncd ..\ntree\nmkdir 02_aligned_reads\ncd 02_aligned_reads\nnice STAR --genomeDir ../01_star_index/ --readFilesIn ../00_source_data/raw_yeast_rnaseq_data.fastq --runThreadN 5 --outFileNamePrefix raw_yeast_rnaseq_data. --outSAMtype BAM SortedByCoordinate\ncd ..\ntree\nmkdir 03_coverage\ncd 03_coverage\nbedtools genomecov -ibam ../02_aligned_reads/raw_yeast_rnaseq_data.Aligned.sortedByCoord.out.bam > raw_yeast_rnaseq_data.genomecov.bg\ncd ..\ntree\nmkdir 04_gene_overlap_counts\ncd 04_gene_overlap_counts\nln -s ../../bioinformatics_on_the_command_line_files/yeast_genes.fixed.bed\nbedtools intersect -c -a yeast_genes.fixed.bed -b ../02_aligned_reads/raw_yeast_rnaseq_data.Aligned.sortedByCoord.out.bam | awk -F'\\t' '$7>0' | sort -k7,7nr > raw_yeast_overlap_data.gene_overlap_counts.bed\ncd ..\ntree\nhead -10 04_gene_overlap_counts/raw_yeast_overlap_data.gene_overlap_counts.bed\ncd ..\n\nWe can see that this works by running the above file (which is saved on the server as ‘/home2/swebb/training/Intro_to_Linux/analysis_raw.sh’):\n\n[USERNAME]@aabn:~/course$ ls\nanalysis  bioinformatics_on_the_command_line_files  bioinformatics_on_the_command_line_files.tar.gz\n[USERNAME]@aabn:~/course$ mv analysis interactive_analysis\n[USERNAME]@aabn:~/course$ ls\nbioinformatics_on_the_command_line_files  bioinformatics_on_the_command_line_files.tar.gz  interactive_analysis\n[USERNAME]@aabn:~/course$ bash /home2/swebb/training/Intro_to_Linux/analysis_raw.sh\n.\n└── 00_source_data\n    └── raw_yeast_rnaseq_data.fastq -> ../../bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq\n\n1 directory, 1 file\nNov 16 16:23:45 ..... started STAR run\nNov 16 16:23:45 ... starting to generate Genome files\nNov 16 16:23:46 ... starting to sort Suffix Array. This may take a long time...\nNov 16 16:23:46 ... sorting Suffix Array chunks and saving them to disk...\nNov 16 16:23:54 ... loading chunks from disk, packing SA...\nNov 16 16:23:55 ... finished generating suffix array\nNov 16 16:23:55 ... generating Suffix Array index\nNov 16 16:23:56 ... completed Suffix Array index\nNov 16 16:23:56 ... writing Genome to disk ...\nNov 16 16:23:56 ... writing Suffix Array to disk ...\nNov 16 16:23:57 ... writing SAindex to disk\nNov 16 16:23:57 ..... finished successfully\n.\n├── 00_source_data\n│   └── raw_yeast_rnaseq_data.fastq -> ../../bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq\n└── 01_star_index\n    ├── chrLength.txt\n    ├── chrNameLength.txt\n    ├── chrName.txt\n    ├── chrStart.txt\n    ├── Genome\n    ├── genomeParameters.txt\n    ├── Log.out\n    ├── SA\n    ├── SAindex\n    └── yeast_genome.fasta -> ../../bioinformatics_on_the_command_line_files/yeast_genome.fasta\n\n2 directories, 11 files\nNov 16 16:23:57 ..... started STAR run\nNov 16 16:23:57 ..... loading genome\nNov 16 16:23:57 ..... started mapping\nNov 16 16:24:00 ..... finished mapping\nNov 16 16:24:00 ..... started sorting BAM\nNov 16 16:24:00 ..... finished successfully\n.\n├── 00_source_data\n│   └── raw_yeast_rnaseq_data.fastq -> ../../bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq\n├── 01_star_index\n│   ├── chrLength.txt\n│   ├── chrNameLength.txt\n│   ├── chrName.txt\n│   ├── chrStart.txt\n│   ├── Genome\n│   ├── genomeParameters.txt\n│   ├── Log.out\n│   ├── SA\n│   ├── SAindex\n│   └── yeast_genome.fasta -> ../../bioinformatics_on_the_command_line_files/yeast_genome.fasta\n└── 02_aligned_reads\n    ├── raw_yeast_rnaseq_data.Aligned.sortedByCoord.out.bam\n    ├── raw_yeast_rnaseq_data.Log.final.out\n    ├── raw_yeast_rnaseq_data.Log.out\n    ├── raw_yeast_rnaseq_data.Log.progress.out\n    ├── raw_yeast_rnaseq_data.SJ.out.tab\n    └── raw_yeast_rnaseq_data._STARtmp\n        └── BAMsort\n            ├── 0\n            ├── 1\n            ├── 2\n            ├── 3\n            └── 4\n\n10 directories, 16 files\n.\n├── 00_source_data\n│   └── raw_yeast_rnaseq_data.fastq -> ../../bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq\n├── 01_star_index\n│   ├── chrLength.txt\n│   ├── chrNameLength.txt\n│   ├── chrName.txt\n│   ├── chrStart.txt\n│   ├── Genome\n│   ├── genomeParameters.txt\n│   ├── Log.out\n│   ├── SA\n│   ├── SAindex\n│   └── yeast_genome.fasta -> ../../bioinformatics_on_the_command_line_files/yeast_genome.fasta\n├── 02_aligned_reads\n│   ├── raw_yeast_rnaseq_data.Aligned.sortedByCoord.out.bam\n│   ├── raw_yeast_rnaseq_data.Log.final.out\n│   ├── raw_yeast_rnaseq_data.Log.out\n│   ├── raw_yeast_rnaseq_data.Log.progress.out\n│   ├── raw_yeast_rnaseq_data.SJ.out.tab\n│   └── raw_yeast_rnaseq_data._STARtmp\n│       └── BAMsort\n│           ├── 0\n│           ├── 1\n│           ├── 2\n│           ├── 3\n│           └── 4\n└── 03_coverage\n    └── raw_yeast_rnaseq_data.genomecov.bg\n\n11 directories, 17 files\n.\n├── 00_source_data\n│   └── raw_yeast_rnaseq_data.fastq -> ../../bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq\n├── 01_star_index\n│   ├── chrLength.txt\n│   ├── chrNameLength.txt\n│   ├── chrName.txt\n│   ├── chrStart.txt\n│   ├── Genome\n│   ├── genomeParameters.txt\n│   ├── Log.out\n│   ├── SA\n│   ├── SAindex\n│   └── yeast_genome.fasta -> ../../bioinformatics_on_the_command_line_files/yeast_genome.fasta\n├── 02_aligned_reads\n│   ├── raw_yeast_rnaseq_data.Aligned.sortedByCoord.out.bam\n│   ├── raw_yeast_rnaseq_data.Log.final.out\n│   ├── raw_yeast_rnaseq_data.Log.out\n│   ├── raw_yeast_rnaseq_data.Log.progress.out\n│   ├── raw_yeast_rnaseq_data.SJ.out.tab\n│   └── raw_yeast_rnaseq_data._STARtmp\n│       └── BAMsort\n│           ├── 0\n│           ├── 1\n│           ├── 2\n│           ├── 3\n│           └── 4\n├── 03_coverage\n│   └── raw_yeast_rnaseq_data.genomecov.bg\n└── 04_gene_overlap_counts\n    ├── raw_yeast_overlap_data.gene_overlap_counts.bed\n    └── yeast_genes.fixed.bed -> ../../bioinformatics_on_the_command_line_files/yeast_genes.fixed.bed\n\n12 directories, 19 files\nXII 460922  466869  RDN37-2 .   -   3730\nXII 451785  457732  RDN37-1 .   -   3582\nXII 468812  468931  RDN5-2  .   +   3063\nXII 468826  468958  YLR154C-H   .   -   3063\nXII 472464  472583  RDN5-3  .   +   3060\nXII 472478  472610  YLR156C-A   .   -   3060\nXII 482044  482163  RDN5-4  .   +   3055\nXII 482058  482190  YLR157C-C   .   -   3055\nXII 485696  485815  RDN5-5  .   +   3052\nXII 485710  485842  YLR159C-A   .   -   3052\n\n[USERNAME]@aabn:~/course$ \n\n\n\nCreating an improved data analysis script\nIn this section we improve our script by doing the following:\n\nAdding a shebang line to the script so that it can be run as a standalone program\nEnsuring that the script does not keep running if one of the commands within it fails\n\nThis is what the set -euo pipefail command at the top of the script does\n\nDeleting unnecessary commands\nAdding spacing and comments to make the script easier to read\n\nIn bash, lines starting with # are taken to be comments\n\nSpecifying inputs as variables in order to make the script more general and easier to maintain, and using paths relative to ‘~’ rather than the current working directory so that the script can be run in any directory and will still find the files\nAdding a few lines to the script to create a run report, which specifies the software versions used for the analysis\n\nThe updated script is shown here:\n\n#!/bin/bash\n# This is simple RNA-Seq analysis workflow that does the following:\n# - Creates a STAR index for the genome fasta file specified in the variable GENOME_FASTA\n# - Aligns the raw reads specified in the fastq file referenced by the variable RAW_FASTQ\n# - Computes the genome coverage of the aligned reads, producing a bedGraph file\n# - Counts the overlaps over the genes specified in the file referenced by the variable GENES_BED\n\nset -euo pipefail\n\n\n# Global variables ----\n\nRAW_FASTQ='~/course/bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq'\nGENOME_FASTA='~/course/bioinformatics_on_the_command_line_files/yeast_genome.fasta'\nGENES_BED='~/course/bioinformatics_on_the_command_line_files/yeast_genes.fixed.bed'\n\nls \"$RAW_FASTQ\" \"$GENOME_FASTA\" \"$GENES_BED\" > /dev/null\n\nRAW_FASTQ_BASENAME_PREFIX=`basename $RAW_FASTQ .fastq`\nGENOME_FASTA_BASENAME=`basename $GENOME_FASTA`\n\nTHREADS=5\n\n\n# Pipeline commands ----\n\n# Create a directory for the results of the analysis\n\nmkdir analysis\ncd analysis\n\n# Link to the fastq containing the raw sequences in '00_source_data'\n\nmkdir 00_source_data\ncd 00_source_data\nln -s \"$RAW_FASTQ\"\ncd ..\n\n# Create a STAR index for the genome fasta file, storing all of the results in '01_star_index'\n\necho 'Creating STAR index...'\n\nmkdir 01_star_index\ncd 01_star_index\nln -s \"$GENOME_FASTA\"\nnice STAR --runThreadN \"$THREADS\" --runMode genomeGenerate --genomeDir . --genomeFastaFiles \"$GENOME_FASTA_BASENAME\" --genomeSAindexNbases 10\ncd ..\n\n# Align the raw sequences using STAR, storing all of the results in '02_aligned_reads'\n\necho 'Aligning raw reads...'\n\nmkdir 02_aligned_reads\ncd 02_aligned_reads\nnice STAR --genomeDir ../01_star_index/ --readFilesIn ../00_source_data/\"$RAW_FASTQ_BASENAME_PREFIX\".fastq --runThreadN \"$THREADS\" --outFileNamePrefix \"$RAW_FASTQ_BASENAME_PREFIX\". --outSAMtype BAM SortedByCoordinate\ncd ..\n\n# Create a genome coverage file in bedGraph format, and store it in '03_coverage'\n\necho 'Creating genome coverage file...'\n\nmkdir 03_coverage\ncd 03_coverage\nbedtools genomecov -ibam ../02_aligned_reads/\"$RAW_FASTQ_BASENAME_PREFIX\".Aligned.sortedByCoord.out.bam > \"$RAW_FASTQ_BASENAME_PREFIX\".genomecov.bg\ncd ..\n\n# Compute the gene overlap counts, and store them as a bed file in '04_gene_overlap_counts'\n\necho 'Computing gene overlap counts...'\n\nmkdir 04_gene_overlap_counts\ncd 04_gene_overlap_counts\nln -s ../../bioinformatics_on_the_command_line_files/yeast_genes.fixed.bed\nbedtools intersect -c -a \"$GENES_BED\" -b ../02_aligned_reads/\"$RAW_FASTQ_BASENAME_PREFIX\".Aligned.sortedByCoord.out.bam | awk -F'\\t' '$7>0' | sort -k7,7nr > \"$RAW_FASTQ_BASENAME_PREFIX\".gene_overlap_counts.bed\ncd ..\n\n# Create a run report\n\necho `realpath $0`\" run completed successfully.\" > run_report.txt\ndate >> run_report.txt\necho 'Software versions:' >> run_report.txt\necho 'STAR' >> run_report.txt\nSTAR --version >> run_report.txt\necho 'bedtools' >> run_report.txt\nbedtools --version | sed 's/^bedtools //' >> run_report.txt\necho 'sort' >> run_report.txt\nsort --version | sed 's/^sort //' | head -1 >> run_report.txt\necho 'awk' >> run_report.txt\nawk --version | head -1 >> run_report.txt\n\n# If we've got here the pipeline has completed successfully\n\necho 'Pipeline completed successfully.'\n\nAgain, we can see that this works by running the above file (which is saved on the server as ‘/home2/swebb/training/Intor_to_Linux/analysis_improved.sh’):\n\n[USERNAME]@aabn:~/course$ ls\nanalysis  bioinformatics_on_the_command_line_files  bioinformatics_on_the_command_line_files.tar.gz interactive_analysis\n[USERNAME]@aabn:~/course$ mv analysis analysis_raw\n[USERNAME]@aabn:~/course$ ls\nanalysis_raw                              bioinformatics_on_the_command_line_files.tar.gz\nbioinformatics_on_the_command_line_files  interactive_analysis\n[USERNAME]@aabn:~/course$ bash /home2/swebb/training/Intro_to_Linux/analysis_improved.sh\nCreating STAR index...\nNov 16 16:38:09 ..... started STAR run\nNov 16 16:38:09 ... starting to generate Genome files\nNov 16 16:38:10 ... starting to sort Suffix Array. This may take a long time...\nNov 16 16:38:10 ... sorting Suffix Array chunks and saving them to disk...\nNov 16 16:38:18 ... loading chunks from disk, packing SA...\nNov 16 16:38:19 ... finished generating suffix array\nNov 16 16:38:19 ... generating Suffix Array index\nNov 16 16:38:20 ... completed Suffix Array index\nNov 16 16:38:20 ... writing Genome to disk ...\nNov 16 16:38:20 ... writing Suffix Array to disk ...\nNov 16 16:38:21 ... writing SAindex to disk\nNov 16 16:38:21 ..... finished successfully\nAligning raw reads...\nNov 16 16:38:21 ..... started STAR run\nNov 16 16:38:21 ..... loading genome\nNov 16 16:38:21 ..... started mapping\nNov 16 16:38:24 ..... finished mapping\nNov 16 16:38:24 ..... started sorting BAM\nNov 16 16:38:24 ..... finished successfully\nCreating genome coverage file...\nComputing gene overlap counts...\nPipeline completed successfully.\n[USERNAME]@aabn:~/course$ cat analysis/run_report.txt\n/home2/swebb/training/Intor_to_Linux/analysis_improved.sh run completed successfully.\nMon 16 Nov 16:38:36 GMT 2020\nSoftware versions:\nSTAR\n2.7.3a\nbedtools\nv2.27.0\nsort\n(GNU coreutils) 8.28\nawk\nGNU Awk 4.1.4, API: 1.1 (GNU MPFR 4.0.1, GNU MP 6.1.2)\n[USERNAME]@bifx-core2:~/course$ \n\n\n\n Challenge:\n\nWhat is the line ls \"$RAW_FASTQ\" \"$GENOME_FASTA\" \"$GENES_BED\" > /dev/null in the script for?\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nIf the files referenced by RAW_FASTQ, GENOME_FASTA, and GENES_BED exist, the line does nothing, as the output of the command is redirected to /dev/null (which basically means that it is ignored). However, if any of the files don’t exist this command will fail with an error message. Because we have included the line set -eou pipefail this will cause the script to stop running, which is what we want if one or more of the output files is missing.\n\n\n\n\n\nManaging your scripts\nOnce you start writing scripts, it is a good idea to use a version control system to keep track of the changes you make to your scripts. A good choice for this would be git. The following five commands will allow you to use git for version control:\n\ngit init to initialise a git repository in the current working directory\ngit add -A; git commit -m \"Latest updates\" to commit any changes to files in the current working directory to the repository\ngit status to see if any changes have been made since the last commit\ngit diff to see the differences between the files in the current working directory and the last commit\ngit show HEAD:[NAME OF FILE IN GIT] to view the most recent version of a file in the git repository\n\nYou can save the output of git show to a file by redirecting its output using >\n\n\nTo learn more about git, you can look at this software carpentry course, which covers it in a lot more detail.\nNote: git should only be used for small text files such as scripts. It is not designed to work with large data files."
  },
  {
    "objectID": "06-scripts.html#closing-thoughts-practical-workflows-on-the-command-line",
    "href": "06-scripts.html#closing-thoughts-practical-workflows-on-the-command-line",
    "title": "Scripts",
    "section": "Closing thoughts: practical workflows on the command line",
    "text": "Closing thoughts: practical workflows on the command line\nIn this section we created a data analysis script in bash that satisfies two major requirements for reproducible data analysis:\n\nThe script provides a complete and accurate record of the steps that were taken to produce the output files, along with a record of the versions of the software tools used to manipulate the data\nThe script is also in a form that would be easy to share with other researchers, allowing them to replicate your analysis easily\n\nThe main drawback of using bash scripts to represent workflows is that they are often impractical. The example presented here uses an extremely small input FASTQ file, and an organism with a relatively small genome. As a result it can be run from scratch in under a minute. Running the same pipeline with a realistically sized input FASTQ file and a larger genome could take hours to run, so it is no longer practical to re-run the pipeline every time you make a change. A workaround for this would be to comment out parts of the script that you do not want to re-run, however this is considered bad practice as it introduces the possibility of human error in selecting the parts of the pipeline that need to be re-run when the pipeline is updated.\nIf you are writing analysis pipelines, you should look into using a modern workflow system such as Snakemake or Nextflow. Workflows written for these workflow systems can be run repeatedly, and the workflow system will automatically work out which steps of the analysis workflow need to be re-run based on the timestamps of the files. They also provide a number of other useful features:\n\nThey work out which steps of the analysis workflow can be run in parallel, and assign steps to different cores when possible, which can speed up the analysis considerably\nThey simplify the process of running workflows on a computing cluster"
  },
  {
    "objectID": "04-processes.html",
    "href": "04-processes.html",
    "title": "Processes",
    "section": "",
    "text": "In this section you will learn how to work with processes and jobs in bash."
  },
  {
    "objectID": "04-processes.html#exploring-processes",
    "href": "04-processes.html#exploring-processes",
    "title": "Processes",
    "section": "Exploring processes",
    "text": "Exploring processes\n\n\n Key points\n\n\nA running program is known as a process. On a modern computer many different processes can run at once\nProcesses are managed by the operating system (Linux in our case)\n\nThe operating system controls how the computer’s resources, such as CPU and disk access, are allocated to the different processes\n\n\n\n\nThere are a few different ways to explore the processes running on your computer:\n\nps shows the processes you are currently running\ntop shows all active processes\nhtop gives a user friendly representation of the processes currently running along with CPU and memory usage on the server\npgrep finds the process IDs of all running instances of a particular program\n\nWe can learn a lot about processes by looking at the output of these commands. For example, if we run the command ps -fly we get something like this:\n\n[USERNAME]@aabn:~/course$ ps -fly\nS UID         PID   PPID   C  PRI  NI   RSS   SZ    WCHAN  STIME TTY          TIME CMD\nS [USERNAME]  35269 35244  0  80   0    39296 13648 wait   Nov10 pts/5    00:00:04 -bash\nR [USERNAME]  44935 35269  0  80   0    3328  8822  -      10:11 pts/5    00:00:00 ps -fly\n...\n\nBy looking at the output columns, we can see the following:\n\nEach process has an owner, whose username is shown in the UID column\nEach process has a unique ID, shown in the PID column\nEach process also has a single parent process, whose ID is shown in the PPID column\n\nThe parent of a process is the process that started it. In our case, the ps -fly process was started by the bash process\nYou can see this by observing that the PPID of the ps -fly process is the same as the PID of the bash process\n\n\n\n\n Challenge:\n\nUse htop to find the following:\n\n\nHow many cores does the server have?\n\n\nHow much memory does it have?\n\n\nWhat is the process ID of the htop process?\n\n\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nRun htop -u [USERNAME] to start htop and display only your own processes. At the top of the htop screen there is a bar chart style representation of each of the cores on the server, showing how busy each core is. The server has 64 cores. There is also a bar entitled Mem, with the total memory shown to its right. The server has 250G of memory. The process ID of htop is in the first column."
  },
  {
    "objectID": "04-processes.html#job-control",
    "href": "04-processes.html#job-control",
    "title": "Processes",
    "section": "Job control",
    "text": "Job control\n\n\n Key points\n\n\nA ‘job’ is a process that is managed by the bash shell, and is a child of the bash process\n\nIn general, whenever you run a command in bash, it starts a job\n\nThe shell keeps track of all of the jobs that it’s currently managing\nRunning a command starts it as a foreground job\n\nWhen a job is run in the foreground you are not shown another command prompt until the job completes.\n\nRunning a command followed by & starts it as a background job\n\nWhen a job is run in the background you are shown another command prompt immediately.\n\n\n\n\nControlling processes and jobs\n\nIn UNIX based systems, jobs and processes can be paused or stopped completely by sending them ‘signals’. There are many signals that you can send (type kill -l to list them all). Arguably the most important are the following:\n\nSIGINT, SIGHUP, and SIGTERM, which request that the process should terminate gracefully\n\nNot all programs respond to these signals.\n\nSIGKILL, which terminates the process immediately\n\nThis should only be used as a last resort, as processes that are sent this signal will not be able close gracefully\n\nSIGTSTP, which suspends the process, and SIGCONT, which restarts a suspended process\n\n\nSending signals to jobs or processes\nThere are many ways to send signals to jobs. Here are some particularly useful ones:\n\nThe kill command sends a specified signal to an individual process or job by ID\n\njobs shows you the names and IDs of all of the jobs that you are currently running in your shell\nYou can also use killall to send a signal to all running instances of a given program, but this is generally a bad idea. It is better to use htop or a combination of pgrep and kill to ensure you only send a signal to the process that you want to\n\nPressing f9 in htop also allows you to send the signal of your choice to the selected process\n\nThere are also some useful keyboard shortcuts to send signals to jobs\n\nCtrl+c sends the SIGINT signal to the current foreground job\nCtrl+z sends the SIGTSTP signal to the current foreground job\n\n\n\nRestarting jobs\nOnce a job has been stopped, it can be restarted in a number of ways:\n\nfg [job ID] restarts a job in the foreground\nbg [job ID] restarts a job in the background\nSend the SIGCONT signal to the job using kill -CONT [job or process ID] or htop\n\n\n\nDisowning jobs\nBy default, jobs you start in your shell are ‘owned’ by your current shell session. As a result, on some servers the job might be terminated when you exit the shell (depending on how bash is configured). You can ensure that this does not happen by ‘disowning’ the job.\n\ndisown [job ID] disowns a currently running job\n\nonce a job has been disowned by the shell, it will disappear from the shell’s job table. The process will become a child of the top level process\n\nnohup can be used to start a job that will definitely not be sent a SIGHUP signal when the shell is closed\n\nUsing nohup also diverts any output that would have gone to the shell to a file called nohup.out\n\n\nThe following example shows how to move a foreground job to the background and disown it:\n\n[USERNAME]@aabn:~/course$ sleep 10000\n<Ctrl+z>\n^Z\n[1]+  Stopped                 sleep 10000\n[USERNAME]@aabn:~/course$ bg %1\n[1]+ sleep 10000 &\n[USERNAME]@aabn:~/course$ jobs\n[1]+  Running                 sleep 10000 &\n[USERNAME]@aabn:~/course$ disown %1\n[USERNAME]@aabn:~/course$ jobs\n[USERNAME]@aabn:~/course$ ps\n  PID TTY          TIME CMD\n29621 pts/1    00:00:00 sleep\n37480 pts/1    00:00:00 bash\n40951 pts/1    00:00:00 ps\n[USERNAME]@aabn:~/course$ \n\nThe example shows that when the sleep 10000 job is disowned it is removed from the jobs list, but the process keeps running.\n\n\n Challenge:\n\nHow could you terminate a foreground job without using Ctrl+c?\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nOne way would be to pause the job with Ctrl+z, and then use kill -INT [job ID] to send a SIGINT signal to the job\n\n\n\n\n\n\n Challenge:\n\nHow could you restart a stopped job that has been disowned?\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nYou could use htop or ps to find the process IDs of the stopped processes, and then use kill -CONT [process ID] to send a SIGCONT signal to those processes."
  },
  {
    "objectID": "00-intro.html",
    "href": "00-intro.html",
    "title": "Introduction",
    "section": "",
    "text": "This introductory course will teach you the basics of performing bioinformatics data analysis on the command line using the GNU bash shell. It covers the following topics:\n\nGetting started with bash\nRunning commands in bash\nNavigating the file system\nManaging files, directories and links\nManaging processes\nBioinformatics data analysis with bash\nCreating bash scripts for reproducible data analysis\n\n\n\nThe GNU bash shell\n\nThe GNU bash shell is one of a range of command line shells that are available for UNIX based operating systems. Modern alternatives include ZSH and the fish shell. Each of these shells provides a high level interface to UNIX based operating systems such as GNU/Linux.\nCommand line shells such as bash provide similar functionality to graphical user interfaces (GUIs), such as those seen in Microsoft Windows and Mac OS X, allowing users to perform tasks such as navigating the file system, running programs, and managing processes and system settings.\n\n\nAdvantages of using a command line shell\n\nWhile command line shells such as bash are not as intuitive for beginners as the point and click interfaces offered by GUI shells, they offer a number of advantages which are very useful for Bioinformatics data analysis:\n\nFlexibility\n\nyou can log in and work on remote machines that may not have a graphical interface or remote desktop server installed\nyou can use bioinformatics tools that don’t have a GUI\n\nReliability\n\nCommand line interfaces take up less memory and system resources than graphical interfaces\nBecause of the complexity of GUI programming, tools with GUIs are more likely to contain bugs\n\nConvenience\n\nPrograms and documentation can be accessed easily\nbash keeps a history of the commands you run and makes it easy to repeat commands\n\nPower\n\nsimple programs can be combined to perform more complex functions\nyou can create scripts for data analysis, without the overhead of creating a GUI\n\n\n\n\nThe UNIX philosophy\n\nThe programs that you will use to interact with the computer using the GNU bash shell have been designed according to the UNIX philosophy, which has been summarised as follows:\n\nWrite programs that do one thing and do it well\nWrite programs to work together\nWrite programs to handle text streams, because that is a universal interface\n\nThis philosophy makes it possible to perform a wide range of complex data analysis tasks by combining a relatively small number of basic commands in different ways. Once you have mastered these basic commands, you’ll find that the bash shell provides an extremely powerful and useful way to manage bioinformatics analyses."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Linux",
    "section": "",
    "text": "This is the homepage for the Introduction to Linux course for biologists at the University of Edinburgh.\n\n\n\nContact shaun.webb@ed.ac.uk for more information."
  },
  {
    "objectID": "05-analysis.html",
    "href": "05-analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "In this section you will learn how to work with common Next Generation Sequencing (NGS) data formats on the command line.\n\nBioinformatics data formats and tools\n\n\n\n Key Points\n\n\nMany standard formats for storing high throughput sequencing data take the form of structured text files, which are easy to manipulate using standard GNU utilities\nMany powerful specialist tools for bioinformatics analysis have been developed to use these formats\n\n\n\nMany of the most common types of file that you will have to work with as a bioinformatician take the form of structured text files, examples include:\n\nStandard formats for representing raw sequences\n\nFASTA\nFASTQ\n\nTabular formats for representing aligned reads or genome features\n\nBED\nSAM\nbedGraph\n\n\nSome other compressed formats, such as BAM, which is a compressed version of the SAM format, can easily be converted to human readable text.\nFurthermore, numerous specialist bioinformatics tools have been specifically developed for working with these file formats. For example:\n\nbedtools and bedops, which work with BED files\nVarious aligners, such as STAR, hisat2, and others, which take raw sequences in FASTQ or FASTA format and align them to the genome\nsamtools, which works with SAM files and BAM files\n\nBAM files can be viewed in SAM format using the samtools view command\n\n\nNote: These tools are not included in most Linux distributions as standard and typically have to be installed separately.\n\n\nWorking with NGS data using GNU tools\n\n\n\n Key Points\n\n\nIt is possible to perform a wide range of complex analysis tasks on NGS data files using standard GNU utilities\nIn this section we illustrate the application of these tools to NGS data\n\n\n\nIn previous sections, we extracted an archive named bioinformatics_on_the_command_line_files.tar.gz into the ~/course directory, creating a directory called ~/course/bioinformatics_on_the_command_line_files. This directory contains a file called yeast_genes.bed, which lists the genomic co-ordinates of 7,126 yeast genes in BED format, and another file called yeast_genome.fasta, which contains the yeast EF4 genome sequence in FASTA format:\n\n[USERNAME]@aabn:~/course$ head -5 bioinformatics_on_the_command_line_files/yeast_genes.bed\nchrI    334 649 YAL069W .   +\nchrI    537 792 YAL068W-A   .   +\nchrI    1806    2169    YAL068C .   -\nchrI    2479    2707    YAL067W-A   .   +\nchrI    7234    9016    YAL067C .   -\n[USERNAME]@aabn:~/course$ head -5 bioinformatics_on_the_command_line_files/yeast_genome.fasta\n>I\nCCACACCACACCCACACACCCACACACCACACCACACACCACACCACACCCACACACACA\nCATCCTAACACTACCCTAACACAGCCCTAATCTAACCCTGGCCAACCTGTCTCTCAACTT\nACCCTCCATTACCCTGCCTCCACTCGTTACCCTGTCCCATTCAACCATACCACTCCGAAC\nCACCATCCATCCCTCTACTTACTACCACTCACCCACCGTTACCCTCCAATTACCCATATC\n[USERNAME]@bifx-core2:~/course$ \n\n\nChecking chromosome names in BED and FASTA files\nLooking at the above outputs, we can see that the naming convention for the chromosomes in the BED file (shown in the first column) appears to be different to the naming convention for the chromosomes in the FASTA file (shown in the first line after the > character). In order to confirm this we would like to produce a sorted list of chromosome names in each file and compare them.\nThe above example demonstrates the following new commands:\n\ncut, which we use to select specified fields (or columns) with the -f option, and specified characters with the -c option\nsort, which sorts the lines it receives from STDIN. The -u flag tells it to remove duplicate lines from the output\ndiff, which compares two text files, and outputs the differences between them\n\nWe can do this as follows:\n\n[USERNAME]@aabn:~/course$ cd bioinformatics_on_the_command_line_files\n[USERNAME]@aabn:~/course/bioinformatics_on_the_command_line_files$ cut -f1 yeast_genes.bed | sort -u > yeast_genes_bed_chromosomes.list \n[USERNAME]@aabn:~/course/bioinformatics_on_the_command_line_files$ grep -E '^>' yeast_genome.fasta | sort -u | cut -c2- > yeast_genome_fasta_chromosomes.list\n[USERNAME]@aabn:~/course/bioinformatics_on_the_command_line_files$ wc -l *_chromosomes.list\n 17 yeast_genes_bed_chromosomes.list\n 17 yeast_genome_fasta_chromosomes.list\n 34 total\n[USERNAME]@aabn:~/course/bioinformatics_on_the_command_line_files$ diff yeast_genes_bed_chromosomes.list yeast_genome_fasta_chromosomes.list \n1,17c1,17\n< chrI\n< chrII\n< chrIII\n< chrIV\n< chrIX\n< chrMT\n< chrV\n< chrVI\n< chrVII\n< chrVIII\n< chrX\n< chrXI\n< chrXII\n< chrXIII\n< chrXIV\n< chrXV\n< chrXVI\n---\n> I\n> II\n> III\n> IV\n> IX\n> MT\n> V\n> VI\n> VII\n> VIII\n> X\n> XI\n> XII\n> XIII\n> XIV\n> XV\n> XVI\n[USERNAME]@aabn:~/course/bioinformatics_on_the_command_line_files$ \n\nAs a result of the commands we ran in the above example, we can see that there is a mismatch between the chromosome names in the BED and FASTA files. Each chromosome name in the BED file is equivalent to the corresponding name in the FASTA file with ‘chr’ added to the start.\nBefore using these files in a bioinformatics analysis, we need to update one of them so that the names match. In the following example we fix the BED file by removing ‘chr’ from the start of each line.\nThe example below uses the sed command, which is used to perform a search and replace style substitution on each line in the BED file using a regular expression. Here, as in the previous examples using grep -E, the ‘^’ character is a regular expression character representing the start of the line. We then confirm that the chromosomes are now the same using the diff command. This produces no output, which means that there are no differences between the chromosome lists.\n\n[USERNAME]@aabn:~/course/bioinformatics_on_the_command_line_files$ sed 's/^chr//' yeast_genes.bed > yeast_genes.fixed.bed\n[USERNAME]@aabn:~/course/bioinformatics_on_the_command_line_files$ cut -f1 yeast_genes.fixed.bed | sort -u > yeast_genes_fixed_bed_chromosomes.list\n[USERNAME]@aabn:~/course/bioinformatics_on_the_command_line_files$ diff yeast_genes_fixed_bed_chromosomes.list yeast_genome_fasta_chromosomes.list\n[USERNAME]@aabn:~/course/bioinformatics_on_the_command_line_files$ rm -i *.list\nrm: remove regular file 'yeast_genes_bed_chromosomes.list'? y\nrm: remove regular file 'yeast_genes_fixed_bed_chromosomes.list'? y\nrm: remove regular file 'yeast_genome_fasta_chromosomes.list'? y\n[USERNAME]@aabn:~/course/bioinformatics_on_the_command_line_files$ \n\n\n\nManipulating BED files with awk and sort\nMany standard formats for representing NGS data take the form of tabular files, in which each line contains a number of fields, separated by a particular character (generally a tab character). The yeast_genes.fixed.bed file generated in the previous example fits this pattern.\nThis example demonstrates how to use awk and sort to find the name and length of the longest gene on chromosome ‘I’ in the yeast_genes.fixed.bed file:\n\n[USERNAME]@aabn:~/course/bioinformatics_on_the_command_line_files$ awk -F'\\t' -v OFS='\\t' '$1==\"I\" {print $4,$3-$2}' yeast_genes.fixed.bed | sort -k2,2nr | head -1\nYAR050W 4614\n[USERNAME]@aabn:~/course/bioinformatics_on_the_command_line_files$ cd ..\n[USERNAME]@aabn:~/course$\n\nThe above example showcases the power of awk in dealing with tabular data. The command awk -F'\\t' -v OFS='\\t' '$1==\"I\" {print $4,$3-$2}' can be decomposed as follows:\n\n-F'\\t' tells awk that the field separator in the input lines is the tab character (\\t)\n-v OFS='\\t' tells awk that the tab character should also be used to separate the fields in the output file\n'$1==\"I\" {print $4,$3-$2}' is an awk program consisting of a single line. Each line of an awk program is a pair with the structure condition {action}, and the program is run on each line of the input. In this example:\n\nThe condition is $1==\"I\", which tells awk that the action should be performed if the first field is equal to “I”\nThe action is print $4,$3-$2, which tells awk to output a line to STDOUT in which the first field is the 4th field of the input line, and the second field is the result of subtracting the 2nd field from the 3rd. In this case the result is the gene length\n\n\nNote: A good resource to learn more about awk is Effective AWK Programming.\nThe sort command in the above example includes the option -k2,2nr. -k tells sort to sort by a key, which comprises a start and stop column number, followed by two options, n, which tells sort that the column contains numbers, and r, which tells sort that the lines should be sorted in reverse (i.e. descending) order.\n\n\n Challenge:\n\nHow could you remove ‘chr’ from the start of each line of yeast_genes.bed without using sed?\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nSince we know that ‘chr’ is at the start of every line, cut -c4- yeast_genes.bed would also work.\n\n\n\n\n\n\n Challenge:\n\nHow would you find the shortest gene on the plus strand of chromosome ‘II’ in yeast_genes.fixed.bed?\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nYou could run awk -F'\\t' -v OFS='\\t' '$1==\"II\"&&$6==\"+\" {print $4,$3-$2}' yeast_genes.fixed.bed | sort -k2,2n | head -1\n\n\n\n\n\n\nCase study: a simple RNA-Seq analysis workflow\n\n\n\n Key Points\n\n\nIt is possible to perform a simple bioinformatics analysis from end to end using only the bash command line\nThis section presents a simple case study using the STAR aligner and bedtools\n\n\n\nIn this section, we will work through a simple pipeline for analysing RNA-Seq data, which involves the following steps:\n\nStart with unaligned reads in FASTQ format\nAlign the reads against an index generated from a target genome, whose sequence is stored in FASTA format, obtaining an output file in BAM format\n\nHere we use the yeast EF4 genome, and align the reads using STAR\n\nCompute the genome coverage of the aligned reads, obtaining an output file in bedGraph format, which can then be viewed in a genome browser\n\nHere we generate the bedGraph file directly from the BED file using bedtools\n\nCount the overlaps between the aligned reads and genomic features, stored in BED format, obtaining an output file in BED format, and find the genes with the largest number of overlapping reads\n\nHere we use bedtools to compute the intersection between the genes and the reference, and use standard GNU utilities to find the genes with the most hits\n\n\nThis analysis uses the files in the ‘bioinformatics_on_the_command_line_files’ directory that we have already been working with, and can be performed as follows:\n\n[USERNAME]@aabn:~/course$ cd ~/course\n[USERNAME]@aabn:~/course$ tree\n.\n├── bioinformatics_on_the_command_line_files\n│   ├── raw_yeast_rnaseq_data.fastq\n│   ├── README\n│   ├── yeast_genes.bed\n│   ├── yeast_genes.fixed.bed\n│   ├── yeast_genome.fasta\n│   └── yeast_genome.fasta.gz\n└── bioinformatics_on_the_command_line_files.tar.gz\n\n1 directory, 7 files\n[USERNAME]@aabn:~/course$ mkdir analysis\n[USERNAME]@aabn:~/course$ cd analysis\n[USERNAME]@aabn:~/course/analysis$ mkdir 00_source_data\n[USERNAME]@aabn:~/course/analysis$ cd 00_source_data\n[USERNAME]@aabn:~/course/analysis/00_source_data$ ln -s ../../bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq \n[USERNAME]@aabn:~/course/analysis/00_source_data$ cd ..\n[USERNAME]@aabn:~/course/analysis$ tree\n.\n└── 00_source_data\n    └── raw_yeast_rnaseq_data.fastq -> ../../bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq\n\n1 directory, 1 file\n[USERNAME]@aabn:~/course/analysis$ mkdir 01_star_index\n[USERNAME]@aabn:~/course/analysis$ cd 01_star_index\n[USERNAME]@aabn:~/course/analysis/01_star_index$ ln -s ../../bioinformatics_on_the_command_line_files/yeast_genome.fasta\n[USERNAME]@aabn:~/course/analysis/01_star_index$ nice STAR --runThreadN 5 --runMode genomeGenerate --genomeDir . --genomeFastaFiles ./yeast_genome.fasta --genomeSAindexNbases 10\nNov 16 15:19:40 ..... started STAR run\nNov 16 15:19:40 ... starting to generate Genome files\nNov 16 15:19:40 ... starting to sort Suffix Array. This may take a long time...\nNov 16 15:19:41 ... sorting Suffix Array chunks and saving them to disk...\nNov 16 15:19:48 ... loading chunks from disk, packing SA...\nNov 16 15:19:49 ... finished generating suffix array\nNov 16 15:19:49 ... generating Suffix Array index\nNov 16 15:19:50 ... completed Suffix Array index\nNov 16 15:19:50 ... writing Genome to disk ...\nNov 16 15:19:50 ... writing Suffix Array to disk ...\nNov 16 15:19:51 ... writing SAindex to disk\nNov 16 15:19:52 ..... finished successfully\n[USERNAME]@aabn:~/course/analysis/01_star_index$ cd ..\n[USERNAME]@aabn:~/course/analysis$ tree\n.\n├── 00_source_data\n│   └── raw_yeast_rnaseq_data.fastq -> ../../bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq\n└── 01_star_index\n    ├── chrLength.txt\n    ├── chrNameLength.txt\n    ├── chrName.txt\n    ├── chrStart.txt\n    ├── Genome\n    ├── genomeParameters.txt\n    ├── Log.out\n    ├── SA\n    ├── SAindex\n    └── yeast_genome.fasta -> ../../bioinformatics_on_the_command_line_files/yeast_genome.fasta\n\n2 directories, 11 files\n[USERNAME]@aabn:~/course/analysis$ mkdir 02_aligned_reads\n[USERNAME]@aabn:~/course/analysis$ cd 02_aligned_reads\n[USERNAME]@aabn:~/course/analysis/02_aligned_reads$ nice STAR --genomeDir ../01_star_index/ --readFilesIn ../00_source_data/raw_yeast_rnaseq_data.fastq --runThreadN 5 --outFileNamePrefix raw_yeast_rnaseq_data. --outSAMtype BAM SortedByCoordinate\nNov 16 15:22:24 ..... started STAR run\nNov 16 15:22:24 ..... loading genome\nNov 16 15:22:24 ..... started mapping\nNov 16 15:22:26 ..... finished mapping\nNov 16 15:22:27 ..... started sorting BAM\nNov 16 15:22:27 ..... finished successfully\n[USERNAME]@aabn:~/course/analysis/02_aligned_reads$ cd ..\n[USERNAME]@aabn:~/course/analysis$ tree\n.\n├── 00_source_data\n│   └── raw_yeast_rnaseq_data.fastq -> ../../bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq\n├── 01_star_index\n│   ├── chrLength.txt\n│   ├── chrNameLength.txt\n│   ├── chrName.txt\n│   ├── chrStart.txt\n│   ├── Genome\n│   ├── genomeParameters.txt\n│   ├── Log.out\n│   ├── SA\n│   ├── SAindex\n│   └── yeast_genome.fasta -> ../../bioinformatics_on_the_command_line_files/yeast_genome.fasta\n├── 02_aligned_reads\n│   ├── raw_yeast_rnaseq_data.Aligned.sortedByCoord.out.bam\n│   ├── raw_yeast_rnaseq_data.Log.final.out\n│   ├── raw_yeast_rnaseq_data.Log.out\n│   ├── raw_yeast_rnaseq_data.Log.progress.out\n│   ├── raw_yeast_rnaseq_data.SJ.out.tab\n│   └── raw_yeast_rnaseq_data._STARtmp\n│       └── BAMsort\n│           ├── 0\n│           ├── 1\n│           ├── 2\n│           ├── 3\n│           └── 4\n├── raw_yeast_rnaseq_data.Aligned.sortedByCoord.out.bam\n├── raw_yeast_rnaseq_data.Log.out\n├── raw_yeast_rnaseq_data.Log.progress.out\n└── raw_yeast_rnaseq_data._STARtmp\n    └── BAMsort\n\n12 directories, 19 files\n[USERNAME]@aabn:~/course/analysis$ mkdir 03_coverage\n[USERNAME]@aabn:~/course/analysis$ cd 03_coverage\n[USERNAME]@aabn:~/course/analysis/03_coverage$ bedtools genomecov -ibam ../02_aligned_reads/raw_yeast_rnaseq_data.Aligned.sortedByCoord.out.bam > raw_yeast_rnaseq_data.genomecov.bg\n[USERNAME]@aabn:~/course/analysis/03_coverage$ cd ..\n[USERNAME]@aabn:~/course/analysis$ tree\n.\n├── 00_source_data\n│   └── raw_yeast_rnaseq_data.fastq -> ../../bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq\n├── 01_star_index\n│   ├── chrLength.txt\n│   ├── chrNameLength.txt\n│   ├── chrName.txt\n│   ├── chrStart.txt\n│   ├── Genome\n│   ├── genomeParameters.txt\n│   ├── Log.out\n│   ├── SA\n│   ├── SAindex\n│   └── yeast_genome.fasta -> ../../bioinformatics_on_the_command_line_files/yeast_genome.fasta\n├── 02_aligned_reads\n│   ├── raw_yeast_rnaseq_data.Aligned.sortedByCoord.out.bam\n│   ├── raw_yeast_rnaseq_data.Log.final.out\n│   ├── raw_yeast_rnaseq_data.Log.out\n│   ├── raw_yeast_rnaseq_data.Log.progress.out\n│   ├── raw_yeast_rnaseq_data.SJ.out.tab\n│   └── raw_yeast_rnaseq_data._STARtmp\n│       └── BAMsort\n│           ├── 0\n│           ├── 1\n│           ├── 2\n│           ├── 3\n│           └── 4\n└── 03_coverage\n    └── raw_yeast_rnaseq_data.genomecov.bg\n\n11 directories, 17 files\n[USERNAME]@aabn:~/course/analysis$ mkdir 04_gene_overlap_counts\n[USERNAME]@aabn:~/course/analysis$ cd 04_gene_overlap_counts\n[USERNAME]@aabn:~/course/analysis/04_gene_overlap_counts$ ln -s ../../bioinformatics_on_the_command_line_files/yeast_genes.fixed.bed\n[USERNAME]@aabn:~/course/analysis/04_gene_overlap_counts$ bedtools intersect -c -a yeast_genes.fixed.bed -b ../02_aligned_reads/raw_yeast_rnaseq_data.Aligned.sortedByCoord.out.bam | awk -F'\\t' '$7>0' | sort -k7,7nr > raw_yeast_overlap_data.gene_overlap_counts.bed\n[USERNAME]@aabn:~/course/analysis/04_gene_overlap_counts$ cd ..\n[USERNAME]@aabn:~/course/analysis$ tree\n.\n├── 00_source_data\n│   └── raw_yeast_rnaseq_data.fastq -> ../../bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq\n├── 01_star_index\n│   ├── chrLength.txt\n│   ├── chrNameLength.txt\n│   ├── chrName.txt\n│   ├── chrStart.txt\n│   ├── Genome\n│   ├── genomeParameters.txt\n│   ├── Log.out\n│   ├── SA\n│   ├── SAindex\n│   └── yeast_genome.fasta -> ../../bioinformatics_on_the_command_line_files/yeast_genome.fasta\n├── 02_aligned_reads\n│   ├── raw_yeast_rnaseq_data.Aligned.sortedByCoord.out.bam\n│   ├── raw_yeast_rnaseq_data.Log.final.out\n│   ├── raw_yeast_rnaseq_data.Log.out\n│   ├── raw_yeast_rnaseq_data.Log.progress.out\n│   ├── raw_yeast_rnaseq_data.SJ.out.tab\n│   └── raw_yeast_rnaseq_data._STARtmp\n│       └── BAMsort\n│           ├── 0\n│           ├── 1\n│           ├── 2\n│           ├── 3\n│           └── 4\n├── 03_coverage\n│   └── raw_yeast_rnaseq_data.genomecov.bg\n└── 04_gene_overlap_counts\n    ├── raw_yeast_overlap_data.gene_overlap_counts.bed\n    └── yeast_genes.fixed.bed -> ../../bioinformatics_on_the_command_line_files/yeast_genes.fixed.bed\n\n12 directories, 19 files\n[USERNAME]@aabn:~/course/analysis$ head -10 04_gene_overlap_counts/raw_yeast_overlap_data.gene_overlap_counts.bed\nXII 460922  466869  RDN37-2 .   -   3730\nXII 451785  457732  RDN37-1 .   -   3582\nXII 468812  468931  RDN5-2  .   +   3063\nXII 468826  468958  YLR154C-H   .   -   3063\nXII 472464  472583  RDN5-3  .   +   3060\nXII 472478  472610  YLR156C-A   .   -   3060\nXII 482044  482163  RDN5-4  .   +   3055\nXII 482058  482190  YLR157C-C   .   -   3055\nXII 485696  485815  RDN5-5  .   +   3052\nXII 485710  485842  YLR159C-A   .   -   3052\n[USERNAME]@aabn:~/course/analysis$ cd ..\n[USERNAME]@aabn:~/course$ \n\nNote: In this analysis we have done everything from scratch, including creating the genome index. For real analyses it is a good idea to use a pre-generated index, as indices for larger genomes take up a lot of space on the server. We have also used nice with the STAR command. It is good practice to use nice with programs such as aligners that could run for a long time and take a lot of resources. nice tells Linux to run the STAR command with low priority so that it doesn’t slow down the server for other users.\n\n\n Challenge:\n\nWe saw earlier that the longest gene on chromosome I is YAR050W. Use bedtools getfasta to find the nucleotide sequence of this gene in FASTA format.\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nRunning bedtools getfasta --help shows us that we need to specify and input DNA FASTA file and a BED file with the feature co-ordinates.  We can extract the feature co-ordinates of YAR050W from yeast_genes.fixed.bed using awk, and use the output of this command with bedtools getfasta. This is illustrated in the following example:\n\n[USERNAME]@bifx-core2:~/course$ bedtools getfasta -fi yeast_genome.fasta -bed <(awk -F'\\t' '$4==\"YAR050W\"' yeast_genes.fixed.bed)\n>I:203402-208016\nATGACAATGCCTCATCGCTATATGTTTTTGGCAGTCTTTACACTTCTGGCACTAACTAGTGTGGCCTCAGGAGCCACAGAGGCGTGCTTACCAGCAGGCCAGAGGAAAAGTGGGATGAATATAAATTTTTACCAGTATTCATTGAAAGATTCCTCCACATATTCGAATGCAGCATATATGGCTTATGGATATGCCTCAAAAACCAAACTAGGTTCTGTCGGAGGACAAACTGATATCTCGATTGATTATAATATTCCCTGTGTTAGTTCATCAGGCACATTTCCTTGTCCTCAAGAAGATTCCTATGGAAACTGGGGATGCAAAGGAATGGGTGCTTGTTCTAATAGTCAAGGAATTGCATACTGGAGTACTGATTTATTTGGTTTCTATACTACCCCAACAAACGTAACCCTAGAAATGACAGGTTATTTTTTACCACCACAGACGGGTTCTTACACATTCAAGTTTGCTACAGTTGACGACTCTGCAATTCTATCAGTAGGTGGTGCAACCGCGTTCAACTGTTGTGCTCAACAGCAACCGCCGATCACATCAACGAACTTTACCATTGACGGTATCAAGCCATGGGGTGGAAGTTTGCCACCTAATATCGAAGGAACCGTCTATATGTACGCTGGCTACTATTATCCAATGAAGGTTGTTTACTCGAACGCTGTTTCTTGGGGTACACTTCCAATTAGTGTGACACTTCCAGATGGTACCACTGTAAGTGATGACTTCGAAGGGTACGTCTATTCCTTTGACGATGACCTAAGTCAATCTAACTGTACTGTCCCTGACCCTTCAAATTATGCTGTCAGTACCACTACAACTACAACGGAACCATGGACCGGTACTTTCACTTCTACATCTACTGAAATGACCACCGTCACCGGTACCAACGGCGTTCCAACTGACGAAACCGTCATTGTCATCAGAACTCCAACAACTGCTAGCACCATCATAACTACAACTGAGCCATGGAACAGCACTTTTACCTCTACTTCTACCGAATTGACCACAGTCACTGGCACCAATGGTGTACGAACTGACGAAACCATCATTGTAATCAGAACACCAACAACAGCCACTACTGCCATAACTACAACTGAGCCATGGAACAGCACTTTTACCTCTACTTCTACCGAATTGACCACAGTCACCGGTACCAATGGTTTGCCAACTGATGAGACCATCATTGTCATCAGAACACCAACAACAGCCACTACTGCCATGACTACAACTCAGCCATGGAACGACACTTTTACCTCTACTTCTACCGAATTGACCACAGTCACCGGTACCAATGGTTTGCCAACTGATGAGACCATCATTGTCATCAGAACACCAACAACAGCCACTACTGCCATGACTACAACTCAGCCATGGAACGACACTTTTACCTCTACTTCTACCGAATTGACCACAGTCACCGGTACCAATGGTTTGCCAACTGATGAGACCATCATTGTCATCAGAACACCAACAACAGCCACTACTGCCATGACTACAACTCAGCCATGGAACGACACTTTTACCTCTACATCCACTGAAATCACCACCGTCACCGGTACCAATGGTTTGCCAACTGATGAGACCATCATTGTCATCAGAACACCAACAACAGCCACTACTGCCATGACTACACCTCAGCCATGGAACGACACTTTTACCTCTACATCCACTGAAATGACCACCGTCACCGGTACCAACGGTTTGCCAACTGATGAAACCATCATTGTCATCAGAACACCAACAACAGCCACTACTGCCATAACTACAACTGAGCCATGGAACAGCACTTTTACCTCTACATCCACTGAAATGACCACCGTCACCGGTACCAACGGTTTGCCAACTGATGAAACCATCATTGTCATCAGAACACCAACAACAGCCACTACTGCCATAACTACAACTCAGCCATGGAACGACACTTTTACCTCTACATCCACTGAAATGACCACCGTCACCGGTACCAACGGTTTGCCAACTGATGAAACCATCATTGTCATCAGAACACCAACAACAGCCACTACTGCCATGACTACAACTCAGCCATGGAACGACACTTTTACCTCTACATCCACTGAAATCACCACCGTCACCGGTACCACCGGTTTGCCAACTGATGAGACCATCATTGTCATCAGAACACCAACAACAGCCACTACTGCCATGACTACAACTCAGCCATGGAACGACACTTTTACCTCTACATCCACTGAAATGACCACCGTCACCGGTACCAACGGCGTTCCAACTGACGAAACCGTCATTGTCATCAGAACTCCAACTAGTGAAGGTCTAATCAGCACCACCACTGAACCATGGACTGGTACTTTCACCTCTACATCCACTGAGATGACCACCGTCACCGGTACTAACGGTCAACCAACTGACGAAACCGTGATTGTTATCAGAACTCCAACCAGTGAAGGTTTGGTTACAACCACCACTGAACCATGGACTGGTACTTTTACTTCTACATCTACTGAAATGACCACCATTACTGGAACCAACGGCGTTCCAACTGACGAAACCGTCATTGTCATCAGAACTCCAACCAGTGAAGGTCTAATCAGCACCACCACTGAACCATGGACTGGTACTTTTACTTCTACATCTACTGAAATGACCACCATTACTGGAACCAATGGTCAACCAACTGACGAAACCGTTATTGTTATCAGAACTCCAACTAGTGAAGGTCTAATCAGCACTACAACGGAACCATGGACCGGTACTTTCACTTCTACATCTACTGAAATGACGCACGTCACCGGTACCAACGGCGTTCCAACTGACGAAACCGTCATTGTCATCAGAACTCCAACCAGTGAAGGTCTAATCAGCACCACCACTGAACCATGGACTGGCACTTTCACTTCGACTTCCACTGAGGTTACCACCATCACTGGAACCAACGGTCAACCAACTGACGAAACTGTGATTGTTATCAGAACTCCAACCAGTGAAGGTCTAATCAGCACCACCACTGAACCATGGACTGGTACTTTCACTTCTACATCTACTGAAATGACCACCGTCACCGGTACTAACGGTCAACCAACTGACGAAACCGTGATTGTTATCAGAACTCCAACCAGTGAAGGTTTGGTTACAACCACCACTGAACCATGGACTGGTACTTTTACTTCGACTTCCACTGAAATGTCTACTGTCACTGGAACCAATGGCTTGCCAACTGATGAAACTGTCATTGTTGTCAAAACTCCAACTACTGCCATCTCATCCAGTTTGTCATCATCATCTTCAGGACAAATCACCAGCTCTATCACGTCTTCGCGTCCAATTATTACCCCATTCTATCCTAGCAATGGAACTTCTGTGATTTCTTCCTCAGTAATTTCTTCCTCAGTCACTTCTTCTCTATTCACTTCTTCTCCAGTCATTTCTTCCTCAGTCATTTCTTCTTCTACAACAACCTCCACTTCTATATTTTCTGAATCATCTAAATCATCCGTCATTCCAACCAGTAGTTCCACCTCTGGTTCTTCTGAGAGCGAAACGAGTTCAGCTGGTTCTGTCTCTTCTTCCTCTTTTATCTCTTCTGAATCATCAAAATCTCCTACATATTCTTCTTCATCATTACCACTTGTTACCAGTGCGACAACAAGCCAGGAAACTGCTTCTTCATTACCACCTGCTACCACTACAAAAACGAGCGAACAAACCACTTTGGTTACCGTGACATCCTGCGAGTCTCATGTGTGCACTGAATCCATCTCCCCTGCGATTGTTTCCACAGCTACTGTTACTGTTAGCGGCGTCACAACAGAGTATACCACATGGTGCCCTATTTCTACTACAGAGACAACAAAGCAAACCAAAGGGACAACAGAGCAAACCACAGAAACAACAAAACAAACCACGGTAGTTACAATTTCTTCTTGTGAATCTGACGTATGCTCTAAGACTGCTTCTCCAGCCATTGTATCTACAAGCACTGCTACTATTAACGGCGTTACTACAGAATACACAACATGGTGTCCTATTTCCACCACAGAATCGAGGCAACAAACAACGCTAGTTACTGTTACTTCCTGCGAATCTGGTGTGTGTTCCGAAACTGCTTCACCTGCCATTGTTTCGACGGCCACGGCTACTGTGAATGATGTTGTTACGGTCTATCCTACATGGAGGCCACAGACTGCGAATGAAGAGTCTGTCAGCTCTAAAATGAACAGTGCTACCGGTGAGACAACAACCAATACTTTAGCTGCTGAAACGACTACCAATACTGTAGCTGCTGAGACGATTACCAATACTGGAGCTGCTGAGACGAAAACAGTAGTCACCTCTTCGCTTTCAAGATCTAATCACGCTGAAACACAGACGGCTTCCGCGACCGATGTGATTGGTCACAGCAGTAGTGTTGTTTCTGTATCCGAAACTGGCAACACCAAGAGTCTAACAAGTTCCGGGTTGAGTACTATGTCGCAACAGCCTCGTAGCACACCAGCAAGCAGCATGGTAGGATATAGTACAGCTTCTTTAGAAATTTCAACGTATGCTGGCAGTGCCAACAGCTTACTGGCCGGTAGTGGTTTAAGTGTCTTCATTGCGTCCTTATTGCTGGCAATTATTTAA\n[USERNAME]@bifx-core2:~/course$ \n\n\n\n\n\n\n\n Challenge:\n\nHow could you use bedtools genomecov to make separate bedGraph files for the plus and minus strands?\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nRunning bedtools genomecov --help shows us that there is a -strand option.  To make a bedGraph file for the plus strand, run bedtools genomecov -strand + -ibam 02_aligned_reads/raw_yeast_rnaseq_data.Aligned.sortedByCoord.out.bam  To make a bedGraph file for the minus strand, run bedtools genomecov -strand - -ibam 02_aligned_reads/raw_yeast_rnaseq_data.Aligned.sortedByCoord.out.bam"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "02-filesystem.html",
    "href": "02-filesystem.html",
    "title": "Filesystem",
    "section": "",
    "text": "In this section you will learn how to explore the Linux file system, and how to create, move, delete and edit files and directories.\n\nIntroducing the Linux file system\n\n\n\n Key Points\n\n\nIn Linux, like other operating systems, the file system is structured as a tree\n\nThe top-level directory is known as the root directory, and is referred to on the command line as /\n\nThe file system contains regular files, directories, and symbolic links to other files\n\nEach file has a unique path in the file system, along with other attributes such as its size, when it was last modified, and the permissions associated with it\n\nEach user’s files are generally stored in a directory called the user’s home directory, also referred to as ~\n\nHome directories are normally found in /home\nOn the aabn server these are also in /home1 and /home2\n\nbash keeps track of the current working directory that the shell is in\n\nWhen a user logs in to a Linux system, it starts in the user’s own home directory by default\n\n\n\n\nThe Linux file system\n\n\nThe Linux file system, where all files in a Linux system are stored, is structured as a tree with a single root directory, known as /, as shown in the above image. The root directory has a number of sub-directories. The most important for us is /home (or /home1 /home2) as this is where users’ home directories are stored. Each user’s files are generally stored in their home directory, and by default users are not permitted to create files outside their own home directory. You can find out the path to your home directory by running the command echo $HOME.\n\n\nFile paths in Linux\n\nFile paths in Linux can be either absolute paths, or relative paths.\n\nAbsolute paths\nEach file in the Linux file system tree is uniquely identified by its absolute path. The absolute path comprises a list of the parent directories of the file, starting from the root directory, separated by the / character, followed by the name of the file. The name of a file, and the path to its parent directory, can be extracted from its path using the basename and dirname commands:\n\n[USERNAME]@aabn:~$ basename /home2/swebb/training/Intro_to_Linux\nIntro_to_Linux\n[USERNAME]@aabn:~$ dirname /home2/swebb/training/Intro_to_Linux\n/home2/swebb/training\n[USERNAME]@aabn:~$ \n\nIn Linux, file names can contain almost any character other than /. However, many characters, including spaces and special characters such as ’ and “, can make files difficult to work with, so, in general, it’s better to stick with letters, numbers, underscores, dashes, and dots when naming files. If you do have to work with a file that contains special characters, you can either put the file path in quotes or use backslashes to escape the special characters:\n\n[USERNAME]@aabn:~$ basename /home2/swebb/training/Intro_to_Linux/file name with spaces\nbasename: extra operand ‘with’\nTry 'basename --help' for more information.\n[USERNAME]@aabn:~$ basename '/home2/swebb/training/Intro_to_Linux/file name with spaces'\nfile name with spaces\n[USERNAME]@aabn:~$ basename /home2/swebb/training/file\\ name\\ with\\ spaces\nfile name with spaces\n[USERNAME]@aabn:~$\n\nNote: Tab completion works with filenames as well as command names.\nThe pwd command shows the absolute path of the current working directory:\n\n[USERNAME]@aabn:~$ pwd\n/home/[USERNAME]\n[USERNAME]@aabn:~$\n\n\n\nRelative paths\nWhile absolute paths provide an unambiguous way of referring to files, they can be cumbersome. For this reason, Linux makes it possible to define paths relative to the current working directory or the user’s home directory:\n\n~ refers to the user’s home directory\n. refers to the current working directory\n.. refers to the parent directory of the current working directory\n\n../.. refers to the parent directory of the parent directory of the current working directory, ../../.. refers to the parent directory of that directory, and so on\n\n\nIf you just use the name of a file, Linux assumes that you are referring to a file in the current working directory.\nThe realpath command can be used to show the absolute path corresponding to a relative path:\n\n[USERNAME]@aabn:~$ realpath ~\n/home2/[USERNAME]\n[USERNAME]@aabn:~$ realpath .\n/home2/[USERNAME]\n[USERNAME]@aabn:~$ realpath ..\n/home2\n[USERNAME]@aabn:~$ \n\n\n\nGlob patterns\nLinux also makes it possible to include wildcards in file paths, making it possible to refer to a group of file paths at once. Paths that include wildcards are called glob patterns. Useful wildcards include:\n\n* which matches any sequence of characters\n? which matches any single character\n[] which matches a single character within the square brackets\n\nfor example, [aA] would match ‘a’ or ‘A’\nranges of numbers are allowed, so [1-5] matches 1, 2, 3, 4, or 5\n\n\nWhen bash sees a glob pattern, it expands it into a list of file paths that match the pattern (separated by spaces). A convenient way to experiment with glob patterns (and to make sure they match the files you want them to) is to use the echo command, which prints its arguments to the command line:\n\n[USERNAME]@aabn:~$ echo /home2/swebb/training/Intro_to_Linux/genomes/*\n/home2/swebb/training/Intro_to_Linux/genomes/human /home2/swebb/training/Intro_to_Linux/genomes/mouse\n[USERNAME]@aabn:~$ echo /home2/swebb/training/Intro_to_Linux/genomes/mouse/mm?\n/home2/swebb/training/Intro_to_Linux/genomes/mouse/mm9\n[USERNAME]@aabn:~$ echo /home2/swebb/training/Intro_to_Linux/genomes/mouse/mm*\n/home2/swebb/training/Intro_to_Linux/genomes/mouse/mm10 /home2/swebb/training/Intro_to_Linux/genomes/mouse/mm9\n[USERNAME]@aabn:~$\n\n\n\n\nFile types and attributes in Linux\n\nThe Linux file system contains three main types of file:\n\nRegular files, which contain data\nDirectories, which contain other files or directories\nSymbolic links, which are aliases (or pointers) to files and folders\n\nAs well as its name and path, each file has a number of attributes associated with it, such as its size, when it was last modified, and the permissions associated with it. You can check the attributes associated with a file using the stat command:\n\n[USERNAME]@aabn:~$ stat /home2/swebb/training/Intro_to_Linux/sequences.fa\n  File: sequences.fa\n  Size: 148         Blocks: 8          IO Block: 4096   regular file\nDevice: fc20h/64544d    Inode: 318242838   Links: 1\nAccess: (0664/-rw-rw-r--)  Uid: (66264/   swebb)   Gid: (66264/   swebb)\nAccess: 2024-02-05 14:21:24.551796452 +0000\nModify: 2024-02-05 14:21:10.695345100 +0000\nChange: 2024-02-05 14:21:20.779673587 +0000\n Birth: -\n[USERNAME]@aabn:~$\n\nThe output of the stat command shows us:\n\nWhat type of file this is (a regular file)\nThe size of the file (148)\nThe identity and group of the owner of the file (root)\nWhen the file was last accessed, modified, and changed\nThe permissions on the file (-rw-rw–r--)\n\nThe first character of the permission string tells us whether it is a file or directory\nThe rest of the string can be divided into three groups (rw-, r–, and r–), representing the permissions granted to the user that owns the file, the group associated with the file, and all users\nThere are three types of permission. These are permission to read the file (r), permission to write to the file (w), and permission to execute the file (x)\n\n\n\n\n Challenge:\n\nCreate a glob pattern that matches /home2/swebb/training/Intro_to_Linux/genomes/mouse/GRCm38 and /home2/swebb/training/Intro_to_Linux/genomes/mouse/UCSC only.\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nOne option would be /home2/swebb/training/Intro_to_Linux/genomes/mouse/[GU]*\n\n\n\n\n\n\n Challenge:\n\nCreate a glob pattern that matches everything in /home2/swebb/training/Intro_to_Linux/genomes/mouse except for /home2/swebb/training/Intro_to_Linux/genomes/mouse/UCSC.\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nOne option would be /home2/swebb/training/Intro_to_Linux/genomes/mouse/*[0-9]\n\n\n\n\n\n\n Challenge:\n\nWho has permission to read the file ‘/home2/swebb/training/Intro_to_Linux/sequences.fa’? Who is permitted to write to it? Is anyone permitted to execute it?\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nEveryone on the server can read the file. The user that owns the file can read and write to it. Nobody is permitted to execute this file.\n\n\n\n\n\n\nExploring the file system\n\n\n\n Key Points\n\n\ncd changes the current working directory\nThe ls command lists the files in the current working directory\nThe find command recursively searches for files in the current file system\n\n\n\nThe following example demonstrates how we can navigate within the file system, and view and find files:\n\n[USERNAME]@aabn:~$ cd /home2/swebb/training/Intro_to_Linux/ \n[USERNAME]@aabn:/home2/swebb/training/Intro_to_Linux/$ ls\nanalysis_improved.sh   analysis_raw.sh   bioinformatics_on_the_command_line_files.tar.gz  'file name with spaces'   genomes   sequences.fa\n[USERNAME]@aabn:/home2/swebb/training/Intro_to_Linux/$ ls -lah\ntotal 3.9M\ndrwxrwxr-x 3 swebb swebb 4.0K Feb  5 14:45  .\ndrwxrwxr-x 3 swebb swebb 4.0K Feb  5 14:06  ..\n-rw-r--r-- 1 swebb swebb 3.2K Feb  5 14:43  analysis_improved.sh\n-rw-r--r-- 1 swebb swebb 1.3K Feb  5 14:43  analysis_raw.sh\n-rw-r--r-- 1 swebb swebb 3.9M Feb  5 14:44  bioinformatics_on_the_command_line_files.tar.gz\n-rw-rw-r-- 1 swebb swebb    0 Feb  5 14:11 'file name with spaces'\ndrwxrwxr-x 4 swebb swebb 4.0K Feb  5 14:14  genomes\n-rw-r--r-- 1 swebb swebb  148 Feb  5 14:21  sequences.fa\n[USERNAME]@aabn:/home2/swebb/training/Intro_to_Linux/$ ls -lah *.gz\n-rw-r--r-- 1 swebb swebb 3.9M Feb  5 14:44 bioinformatics_on_the_command_line_files.tar.gz\n[USERNAME]@aabn:/home2/swebb/training/Intro_to_Linux/$ find genomes/mouse/mm10/ -type f -name '*.bed'\ngenomes/mouse/mm10/cpg_islands.bed\ngenomes/mouse/mm10/genes.bed\ngenomes/mouse/mm10/repeats.bed\n[USERNAME]@aabn:/home2/swebb/training/Intro_to_Linux/$ cd\n[USERNAME]@aabn:~$ \n\nNote: In this example we have used the command ls -lah. This is an example of a shorthand that you can use in the bash shell when specifying multiple flags. ls -lah is equivalent to ls -l -a -h.\n\n\n Challenge:\n\nList all of the paths to files named ‘genome.fa’ in the directory ‘/home2/swebb/training/Intro_to_Linux/genomes’\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nRun find /home2/swebb/training/Intro_to_Linux/genomes/mouse/ -type f -name 'genome.fa'\n\n\n\n\n\n\n Challenge:\n\nUsing the commands you’ve learned in this section, explore the /home2/swebb/training/Intro_to_Linux/genomes/ directory on the server. Which organisms do we have genomes for? Which genome releases do we have for each of these organisms?\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nRun ls /home2/swebb/training/Intro_to_Linux/genomes/ to list the organisms in that folder. Run find /home2/swebb/training/Intro_to_Linux/genomes/ -maxdepth 2 -type d to list the sub-directories of the directories representing the organisms, which represent genome releases.\n\n\n\n\n\nCreating and deleting files\n\n\n\n Key Points\n\n\nFiles can be created using touch, by a text editor, or by redirecting the output of a program\nSymbolic links can be created using ln -s\nDirectories can be created using mkdir, and empty directories can be removed using rmdir\nThe rm command can be used to delete files, links, and directories along with their contents (using the -r flag)\n\nThere is no recycle bin in Linux, so rm should be used with care. The -i flag can be used to prompt for confirmation before deleting files\n\n\n\nThe following example demonstrates how we can create and remove files, directories and links:\n\n[USERNAME]@aabn:~$ cd\n[USERNAME]@aabn:~$ mkdir course\n[USERNAME]@aabn:~$ cd course\n[USERNAME]@aabn:~/course$ mkdir -p dir1 dir2 dir3/dir4\n[USERNAME]@aabn:~/course$ tree\n.\n├── dir1\n├── dir2\n└── dir3\n    └── dir4\n    \n4 directories, 0 files\n[USERNAME]@aabn:~/course$ touch file1\n[USERNAME]@aabn:~/course$ tree\n.\n├── dir1\n├── dir2\n├── dir3\n│   └── dir4\n└── file1\n\n4 directories, 1 file\n[USERNAME]@aabn:~/course$ cd dir1\n[USERNAME]@aabn:~/course$ ln -s ../file1\n[USERNAME]@aabn:~/course$ cd ..\n[USERNAME]@aabn:~/course$ tree\n.\n├── dir1\n│   └── file1 -> ../file1\n├── dir2\n├── dir3\n│   └── dir4\n└── file1\n\n4 directories, 2 files\n[USERNAME]@aabn:~/course$ rmdir *\nrmdir: failed to remove 'dir1': Directory not empty\nrmdir: failed to remove 'dir3': Directory not empty\nrmdir: failed to remove 'file1': Not a directory\n[USERNAME]@aabn:~/course$ tree\n.\n├── dir1\n│   └── file1 -> ../file1\n├── dir3\n│   └── dir4\n└── file1\n\n3 directories, 2 files\n[USERNAME]@aabn:~/course$ rm -ri *\nrm: descend into directory 'dir1'? y\nrm: remove symbolic link 'dir1/file1'? y\nrm: remove directory 'dir1'? n\nrm: descend into directory 'dir3'? y\nrm: remove directory 'dir3/dir4'? y\nrm: remove directory 'dir3'? y\nrm: remove regular empty file 'file1'? n\n[USERNAME]@aabn:~/course$ tree\n.\n├── dir1\n└── file1\n\n1 directory, 1 file\n[USERNAME]@aabn:~/course$ rmdir dir1\n[USERNAME]@aabn:~/course$ rm -i file1\nrm: remove regular empty file 'file1'? y\n[USERNAME]@aabn:~/course$ tree\n.\n\n0 directories, 0 files\n[USERNAME]@aabn:~/course$\n\nThe example demonstrates a number of commands:\n\ntouch to create an empty file\n\nThis can also be used to update the timestamp on an existing file\n\nmkdir to create empty directories\n\nAdd -p to create nested directories by specifying paths\n\nln -s to create a symbolic link to a file or directory\nrmdir to delete empty directories, without deleting files or non-empty directories\nrm command\n\nAdd -r to remove directories (and their contents)\nAdd -i to ask for confirmation before deleting\n\n\n\n\nCopying and moving files and directories\n\n\n\n Key Points\n\n\nFiles and directories can be copied using cp\n\nTo copy a directory along with its contents, use the -r flag\n\nArchive files in tar format can be extracted using the tar command\nDirectories can be synchronised using rsync, which only copies updated files\nFiles and directories can be moved or renamed using mv\nAttributes of files and directories can be changed using chmod\n\nchmod changes the permissions on a file\n\n\n\n\nThe following example demonstrates how we can copy files and directories, extract archive files and update file permissions:\n\n[USERNAME]@aabn:~/course$ cp /home2/swebb/training/Intro_to_Linux/bioinformatics_on_the_command_line_files.tar.gz .\n[USERNAME]@aabn:~/course$ tar -xzvf bioinformatics_on_the_command_line_files.tar.gz\nbioinformatics_on_the_command_line_files/\nbioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq\nbioinformatics_on_the_command_line_files/yeast_genome.fasta\nbioinformatics_on_the_command_line_files/README\nbioinformatics_on_the_command_line_files/yeast_genes.bed\n[USERNAME]@aabn:~/course$ tree\n.\n├── bioinformatics_on_the_command_line_files\n│   ├── raw_yeast_rnaseq_data.fastq\n│   ├── README\n│   ├── yeast_genes.bed\n│   └── yeast_genome.fasta\n└── bioinformatics_on_the_command_line_files.tar.gz\n\n1 directory, 5 files\n[USERNAME]@aabn:~/course$ cp -a -r bioinformatics_on_the_command_line_files bioinformatics_on_the_command_line_files-copy\n[USERNAME]@aabn:~/course$ tree\n.\n├── bioinformatics_on_the_command_line_files\n│   ├── raw_yeast_rnaseq_data.fastq\n│   ├── README\n│   ├── yeast_genes.bed\n│   └── yeast_genome.fasta\n├── bioinformatics_on_the_command_line_files-copy\n│   ├── raw_yeast_rnaseq_data.fastq\n│   ├── README.txt\n│   ├── yeast_genes.bed\n│   └── yeast_genome.fasta\n└── bioinformatics_on_the_command_line_files.tar.gz\n\n2 directories, 9 files\n[USERNAME]@aabn:~/course$ mv bioinformatics_on_the_command_line_files-copy/README README.txt\n[USERNAME]@aabn:~/course$ tree\n.\n├── bioinformatics_on_the_command_line_files\n│   ├── raw_yeast_rnaseq_data.fastq\n│   ├── README\n│   ├── yeast_genes.bed\n│   └── yeast_genome.fasta\n├── bioinformatics_on_the_command_line_files-copy\n│   ├── raw_yeast_rnaseq_data.fastq\n│   ├── yeast_genes.bed\n│   └── yeast_genome.fasta\n├── bioinformatics_on_the_command_line_files.tar.gz\n└── README.txt\n\n2 directories, 9 files\n\n[USERNAME]@aabn:~/course$ rm -r -i bioinformatics_on_the_command_line_files-copy README.txt\nrm: descend into directory 'bioinformatics_on_the_command_line_files-copy/'? y\nrm: remove regular file 'bioinformatics_on_the_command_line_files-copy/s.cerevisiae_genome.fasta'? y\nrm: remove regular file 'bioinformatics_on_the_command_line_files-copy/raw_s.cerevisiae_rnaseq_data.fastq'? y\nrm: remove regular file 'bioinformatics_on_the_command_line_files-copy/README'? y\nrm: remove regular file 'bioinformatics_on_the_command_line_files-copy/s.cerevisiae_genes.bed'? y\nrm: remove directory 'bioinformatics_on_the_command_line_files-copy/'? y\nrm: remove regular file 'README.txt'? y\n[USERNAME]@aabn:~/course$ tree\n.\n├── bioinformatics_on_the_command_line_files\n│   ├── raw_yeast_rnaseq_data.fastq\n│   ├── README\n│   ├── yeast_genes.bed\n│   └── yeast_genome.fasta\n└── bioinformatics_on_the_command_line_files.tar.gz\n\n1 directory, 5 files\n[USERNAME]@aabn:~/course$ chmod a-w bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq\n[USERNAME]@aabn:~/course$ rm bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq\nrm: remove write-protected regular file 'bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq'? n\n[USERNAME]@aabn:~/course$\n\nThis example has demonstrated a number of commands:\n\ncp to copy files and directories (with the -r flag set)\n\nThe -a flag preserves file attributes when they are copied\n\nmv to move files or directories\nchmod to change the permissions on a file\n\nIt’s always a good idea to make raw data files read only as we did in the example, as it makes it more difficult to remove or overwrite them accidentally\nCheck the chmod man page for more details"
  },
  {
    "objectID": "03-files.html",
    "href": "03-files.html",
    "title": "Files",
    "section": "",
    "text": "In this section you will learn how to explore and manipulate files in bash using simple commands, and compound commands using pipes.\n\nExploring files\n\n\n\n Key Points\n\n\nRegular files in Linux can be classified as text files, which contain human readable text, and binary files, that contain data that is not human readable\nThe cat command can be used to show the contents of a file\n\nThe less command allows you to page through a large file\n\nThe head and tail commands can be used to show the first or last few lines of a file\n\nThese can be useful for large text files\n\nThe wc -l command counts the number of lines in a file\nThe grep command allows you to filter a text file\nText files can be compressed using the gzip command, which converts them to a binary format that takes up less space\n\nMany of the above commands for working with text files have equivalents for gzipped files\nThese include zcat, zless, and zgrep\n\n\n\n\nThe following example demonstrates how we can explore text files:\n\n[USERNAME]@aabn:~/course$ tree\n.\n├── bioinformatics_on_the_command_line_files\n│   ├── raw_yeast_rnaseq_data.fastq\n│   ├── README\n│   ├── yeast_genes.bed\n│   └── yeast_genome.fasta\n└── bioinformatics_on_the_command_line_files.tar.gz\n\n1 directory, 5 files\n[USERNAME]@aabn:~/course$ cat bioinformatics_on_the_command_line_files/README\nThis archive contains reference files for the 'Introduction to Bioinformatics on the Command Line' course. In the course you will learn how to build a simple pipeline to analyse some yeast RNA-Seq data using these files. The following files are included:\n\n- raw_yeast_rnaseq_data.fastq: This is a file containing 10,000 raw reads taken from a yeast RNA-Seq experiment\n- yeast_genome.fasta: This file contains the reference genome sequence for yeast (EF4) in fasta format\n- yeast_genes.bed: This file contains the genomic co-ordinates of yeast genes in bed format\n[USERNAME]@aabn:~/course$ less bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq\n...\n<q>\n[USERNAME]@aabn:~/course$ head -5 bioinformatics_on_the_command_line_files/yeast_genome.fasta\n>I\nCCACACCACACCCACACACCCACACACCACACCACACACCACACCACACCCACACACACA\nCATCCTAACACTACCCTAACACAGCCCTAATCTAACCCTGGCCAACCTGTCTCTCAACTT\nACCCTCCATTACCCTGCCTCCACTCGTTACCCTGTCCCATTCAACCATACCACTCCGAAC\nCACCATCCATCCCTCTACTTACTACCACTCACCCACCGTTACCCTCCAATTACCCATATC\n[USERNAME]@aabn:~/course$ tail -5 bioinformatics_on_the_command_line_files/yeast_genome.fasta\nGTGTTTGTTGCACGGCAGTAGCGAGAGACAAGTGGGAAAGAGTAGGATAAAAAGACAATC\nTATAAAAAGTAAACATAAAATAAAGGTAGTAAGTAGCTTTTGGTTGAACATCCGGGTAAG\nAGACAACAGGGCTTGGAGGAGACGTACATGAGGGCTATTTAGGGCTATTTAGGGCTATGT\nAGAAGTGTTGTAGGGCTAAAGAACAGGGTTTCATTTTCATTTTTTTTTTTTAATTTCGGT\nCAGAAA\n[USERNAME]@aabn:~/course$ wc -l bioinformatics_on_the_command_line_files/yeast_genes.bed\n7126 bioinformatics_on_the_command_line_files/yeast_genes.bed\n[USERNAME]@aabn:~/course$\n\nThe grep command can search and filter files:\n\ngrep expression filename returns all the lines with the word ‘expression’ in the file called ‘filename’.\ngrep -i is case insensitive\ngrep -c will count the number of lines matching an expression\ngrep -v returns all of the lines that do not match an expression\n\n\n[USERNAME]@aabn:~/course$ grep format bioinformatics_on_the_command_line_files/README\nThis archive contains reference files for the 'Introduction to Bioinformatics on the Command Line' course. In the course you will learn how to build a simple pipeline to analyse some yeast RNA-Seq data using these files. The following files are included:\n- yeast_genome.fasta: This file contains the reference genome sequence for yeast (EF4) in fasta format\n- yeast_genes.bed: This file contains the genomic co-ordinates of yeast genes in bed format\n[USERNAME]@aabn:~/course$ grep -v format bioinformatics_on_the_command_line_files/README\n\n- raw_yeast_rnaseq_data.fastq: This is a file containing 10,000 raw reads taken from a yeast RNA-Seq experiment\n[USERNAME]@aabn:~/course$ grep -c -E '^>' bioinformatics_on_the_command_line_files/yeast_genome.fasta\n17\n[USERNAME]@aabn:~/course$\n\nNote: The -E flag in grep allows you to use a regular expression to specify a pattern that grep will look for rather than a fixed string. Conceptually, regular expressions are similar to glob patterns, although their syntax is different. Some characters have a special meaning in regular expressions. For example:\n\n^ represents the start of a string\n$ represents the end of a string\n.* represents a sequence of zero or more characters\n.+ represents a sequence of one or more characters\n\nCompressed files can be unzipped with the gzip command:\n\n\n[USERNAME]@aabn:~/course$ gzip -k bioinformatics_on_the_command_line_files/yeast_genome.fasta\n[USERNAME]@aabn:~/course$ ls -lh bioinformatics_on_the_command_line_files/yeast_genome.fasta*\n-rw-rw-r-- 1 [USERNAME] [USERNAME]  12M Nov 12 12:38 bioinformatics_on_the_command_line_files/yeast_genome.fasta\n-rw-rw-r-- 1 [USERNAME] [USERNAME] 3.7M Nov 12 12:38 bioinformatics_on_the_command_line_files/yeast_genome.fasta.gz\n[USERNAME]@baabn:~/course$ zgrep -c -E '^>' bioinformatics_on_the_command_line_files/yeast_genome.fasta.gz\n17\n[USERNAME]@aabn:~/course$\n\n\n\n Challenge:\n\nHow would you check that every line of the ‘yeast_genes.bed’ file starts with the string ‘chr’ without looking through the whole file?\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nRun grep -v -c -E '^chr' bioinformatics_on_the_command_line_files/yeast_genes.bed to count the number of lines that don’t start with ‘chr’. We can see that this is zero, so every line must start with ‘chr’.\n\n\n\n\n\nShell redirection\n\n\n\n Key Points\n\n\nThe shell can manage where programs receive inputs from and where they send outputs to\nIt provides three I/O channels for programs to use. These are:\n\nStandard input, or STDIN, which provides input to the program\nStandard output, or STDOUT, which receives output from the program\nStandard error, or STDERR, which receives error messages from the program\n\nProgram authors don’t have to use these I/O channels, but most command line tools designed for Linux, such as the GNU coreutils, do use them\nBy default, STDIN comes from the keyboard, and STDOUT and STDERR go to the terminal, but each of these channels can be redirected\n\n> redirects STDOUT to an output file, overwriting its contents\n>> redirects STDOUT to an output file, appending to its contents\n2> redirects STDERR to an output file, overwriting its contents\n2>> redirects STDERR to an output file, appending to its contents\n< reads each line from an input file and feeds it to STDIN\n2>&1 redirects STDERR to STDOUT\n\n\n\n\nThe following example demonstrates how shell redirection works:\n\n[USERNAME]@aabn:~/course$ echo zero > output.txt\n[USERNAME]@aabn:~/course$ cat < output.txt\nzero\n[USERNAME]@aabn:~/course$ echo one > output.txt\n[USERNAME]@aabn:~/course$ cat < output.txt\none\n[USERNAME]@aabn:~/course$ echo two >> output.txt\n[USERNAME]@aabn:~/course$ cat < output.txt\none\ntwo\n[USERNAME]@aabn:~/course$ cat bioinformatics_on_the_command_line_files/README > cat_readme.out 2> cat_readme.err\n[USERNAME]@aabn:~/course$ head -2 cat_readme.*\n==> cat_readme.err <==\n\n==> cat_readme.out <==\nThis archive contains reference files for the 'Introduction to Bioinformatics on the Command Line' course. In the course you will learn how to build a simple pipeline to analyse some yeast RNA-Seq data using these files. The following files are included:\n\n[USERNAME]@aabn:~/course$ zcat bioinformatics_on_the_command_line_files/README > zcat_readme.out 2> zcat_readme.err\n[USERNAME]@aabn:~/course$ head -2 zcat_readme.*\n==> zcat_readme.err <==\n\ngzip: bioinformatics_on_the_command_line_files/README: not in gzip format\n\n==> zcat_readme.out <==\n[USERNAME]@aabn:~/course$ zcat bioinformatics_on_the_command_line_files/README > zcat_readme.all 2>&1\n[USERNAME]@aabn:~/course$ cat zcat_readme.all\n\ngzip: bioinformatics_on_the_command_line_files/README: not in gzip format\n[USERNAME]@aabn:~/course$ rm -i *cat_readme.* output.txt\nrm: remove regular empty file 'cat_readme.err'? y\nrm: remove regular file 'cat_readme.out'? y\nrm: remove regular file 'zcat_readme.all'? y\nrm: remove regular file 'zcat_readme.err'? y\nrm: remove regular empty file 'zcat_readme.out'? y\nrm: remove regular file 'output.txt'? y\n[USERNAME]@aabn:~/course$ \n\n\n\nCreating compound commands using pipes\n\n\n\n Key Points\n\n\nBecause the shell provides standard input and output channels, it is possible to chain together simple commands to perform complex tasks\nThis can be done using a ‘pipe’, represented by the pipe character |\n\n\n\nSo far we have discussed simple commands, which consist of a single command name followed by some options and arguments. However, a lot of the flexibility of the tools accessible via bash comes from the ability to combine them to form compound commands, using pipes. This allows the user to perform complex tasks by joining together simple commands.\nMotivating example: How do you count how many of the first 40 lines in a FASTQ file contain the sequence ACTG?\nHere’s how you could do it using simple commands:\n\n[USERNAME]@aabn:~/course$ head -40 bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq > first_40_lines.tmp\n[USERNAME]@aabn:~/course$ grep -c ACTG first_40_lines.tmp\n5\n[USERNAME]@aabn:~/course$ rm -i first_40_lines.tmp\nrm: remove regular file 'first_40_lines.tmp'? y\n[USERNAME]@aabn:~/course$ \n\nHere’s how you can do it in a single command using a pipe:\n\n[USERNAME]@aabn:~/course$ head -40 bioinformatics_on_the_command_line_files/raw_yeast_rnaseq_data.fastq | grep -c ACTG\n5\n[USERNAME]@aabn:~/course$ \n\nPipes are particularly useful for working with large files, as they remove the need to create large intermediate files, which may take up space. They can also save time, as commands can sometimes start working on the data produced by commands preceding them in the pipeline before they have finished running, and in some cases preceding commands can be terminated early if further outputs are no longer needed.\n\n\n Challenge\n\nWe can find how long it takes to find the first line in ‘/homes/genomes/mouse/UCSC/mm10/Sequence/WholeGenomeFasta/genome.fa’ that contains the character ‘A’ by writing all matches to a temporary file and then finding the first line using head as follows:\n\n[USERNAME]@aabn:~/course$ time grep A /homes/genomes/mouse/UCSC/mm10/Sequence/WholeGenomeFasta/genome.fa > grepA.tmp\n\nreal    0m36.182s\nuser    0m7.831s\nsys     0m6.377s\n[USERNAME]@aabn:~/course$ time head -1 grepA.tmp\ngcttcagaataatcatattattctcaaattttgtatcaatataaaaaaaA\n\nreal    0m0.008s\nuser    0m0.001s\nsys     0m0.003s\n[USERNAME]@aabn:~/course$ rm -ri grepA.tmp\nrm: remove regular file 'grepA.tmp'? y\n[USERNAME]@aabn:~/course$ \n\nWe can see that the operation takes just over 36 seconds. Using the time command, find the length of time it takes to perform the same task using a pipe. Is there much of a difference? Why?\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nTo find out how long it takes to find the line with a pipe you can do the following:\n\n[USERNAME]@aabn:~/course$ time grep A /homes/genomes/mouse/UCSC/mm10/Sequence/WholeGenomeFasta/genome.fa | head -1\ngcttcagaataatcatattattctcaaattttgtatcaatataaaaaaaA\n\nreal    0m0.011s\nuser    0m0.002s\nsys 0m0.012s\n\nAs we can see the operation completes in about 0.01 seconds, so using a pipe is considerably faster. This is because the pipeline stops when it has found the first match, so the grep command doesn’t have to go through the whole file.\nNote: it is actually possible to find the first match quickly using a single grep command and no pipe, by using the -m option in grep."
  },
  {
    "objectID": "01-start.html",
    "href": "01-start.html",
    "title": "Getting Started",
    "section": "",
    "text": "In this section you will learn how to log into the WCB’s bifx servers, and run some simple commands. You will also learn how to find out about commands, and how to use bash efficiently.\n\nStarting a Terminal and logging in to the remote server\n\nThe process of starting a terminal depends on the operating system that you are using:\n\nOn Mac OS X or Ubuntu Linux, simply open the ‘Terminal’ application\nOn Windows, you can install MobaXTerm\n\nYou can log in to the server by typing the following command in the Terminal, substituting [USERNAME] for your account username:\n\nssh [USERNAME]@aabn.ug.edu.gh\n\nIf you are using MobaXTerm, an alternative way of logging into the server is shown in the MobaXTerm demo.\nOnce you have typed in your password, you should see some welcome text and a prompt that looks something like this:\n\n[USERNAME]@aabn:~$\n\nThis prompt shows you that you are logged in to the aabn bioinformatics server, and that you are in your home directory (which is referred to using the ~ character on Linux systems).\n\n\nRunning basic commands in bash\n\n\n\n Key Points\n\n\nCommands in bash can be categorised as either:\n\nbuilt in commands (or builtins), which are part of the bash shell, or\ninstalled programs, which could be either the basic GNU core utilities (or coreutils), included in most Linux distributions, or other programs, such as specialised bioinformatics tools\n\n\n\nIn order to run a command in bash you type the command and then press the return key to execute it. For example, try typing date at the prompt and pressing return. You should get something like this:\n\n[USERNAME]@aabn:~$ date\nWed 31 Jan 09:21:43 GMT 2024\n[USERNAME]@aabn:~$ \n\nAs you can see, the output of the date command is printed on the command line, and then another prompt is shown.\nAs well as the command name, a command can include ‘options’ and ‘arguments’. For example, try typing date -d '25 Dec' +%j at the command line:\n\n[USERNAME]@aabn:~$ date -d '25 Dec' +%j\n360\n[USERNAME]@aabn:~$ \n\nIn this example, the command includes the following elements:\n\nthe command name date, which always comes first\none option -d '25 Dec', which has a name -d (option names always start with at least one ‘-’), and a value '25 Dec'\none argument +%j\n\n\nOptions and arguments\nOptions always have a name, but do not always need to have an associated value. Options that don’t have a value are called flags, and are often used as switches for different kinds of functionality. Unlike options, arguments don’t have names. Instead they are identified by their position.\nIn general, the values of options and arguments are text strings, which are passed directly to the command. If a value contains spaces, you can surround it with quote marks, as in the example above, so that it is recognised as a single value. You can also use the output of one command as an argument to another by enclosing it in backticks ```, as in the following example:\n\n[USERNAME]@aabn:~$ echo date\ndate\n[USERNAME]@aabn:~$ echo `date`\nSat 14 Nov 11:25:11 GMT 2020\n[USERNAME]@aabn:~$ \n\nNote: The above example uses the echo command, which outputs the text value of its arguments.\n\n\n\nFinding out about bash commands\n\n\n\n Key Points\n\n\nThe bash shell provides a number of different ways to access information about commands, in particular:\n\nThe man command\nThe info command\n--help and -h flags\n\n\n\nWhile the use of options and arguments makes commands more powerful and flexible, they can be difficult to remember, and can vary between different versions of the command. For this reason, it is useful to be able to find information about commands easily.\n\nThe man command\nThis displays a short manual page for a single command. To see the manual page for the date command simply type man date.\n\nYou can scroll through the man page using space, and type q to quit\n\nYou can learn more about different commands by typing h\n\nTo learn about bash builtins, type man builtins\n\n\n\nThe info command\nThis displays a more comprehensive hyperlinked manual, which provides detailed information about the GNU coreutils. Simply type info to see the info documentation, and type H in info to find out how to navigate the documentation. Press q to quit.\n\n\n--help and -h flags\nSome programs may not have any documentation that is accessible using the man or info commands. In this case, they may follow the convention of including --help or -h flags, which will show some usage information. As an example, we can try to find help information about bedtools, which is a well known bioinformatics tool that we will look at later in the course:\n\n[USERNAME]@aabn:~$ man bedtools\nNo manual entry for bedtools\nSee 'man 7 undocumented' for help when manual pages are not available.\n[USERNAME]@aabn:~$ info bedtools\ninfo: No menu item 'bedtools' in node '(dir)Top'\n[USERNAME]@aabn:~$ bedtools --help\nbedtools is a powerful toolset for genome arithmetic.\n\nVersion:   v2.30.0\n...\n\n\n\n Challenge:\n\nWe saw the command “date -d ‘25 Dec’ +%j” in the previous section. Can you use the man command to explain what it does?\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nRun man date, and look for the -d flag. The documentation explains that -d tells date to display the time described by the value of the option, rather than the current time. Now look up %j in the documentation. The relevant line says ‘%j day of year (001..366)’. So the command tells you which day of the year it will be on the 25th of December.\n\n\n\n\n\n\nUsing bash efficiently\n\n\n\n Key Points\n\n\nWorking with long commands in bash can be laborious, but luckily there are a few tricks that you can use to make things easier. These are:\n\nKeyboard shortcuts\nTab completion\nUsing the bash history\n\n\n\n\nKeyboard shortcuts\nBy default, bash allows you to use many keyboard shortcuts from the GNU Emacs editor to work with your commands. These include:\n\nCtrl+a to move to the beginning of the line\nCtrl+e to move to the end of the line\nCtrl+k to cut the text from the cursor to the end of the line\nCtrl+y to paste text at the cursor\nCtrl+l to clear the terminal\n\nYou can also use Ctrl+c to terminate the command that is currently running and take you back to the command prompt.\n\n\nTab completion\nTab completion allows you to type part of a command name followed by the Tab key, which prompts bash to guess the rest of the command name based on the commands that are available on the system.\nFor instance, if you want to run the bedtools command on the server, you can type bedt followed by Tab, and the rest of the command name will be filled in for you.\nTyping Tab once to complete a command name only works if there is only one possible way to complete the name. If there are multiple options and you would like to see them, you can type Tab twice, and the possible completions will be displayed.\n\n\nUsing the bash history\nA particularly useful feature of command line shells is the ability to look back at previous commands that you have run. In bash you can access these commands using the history command. Typing history will show you a numbered list of commands you’ve run recently. You can also specify the number of previous commands you’d like to see by including it as an argument.\nThere are a few useful tricks that make it easy to find and run commands that you have run before:\n\nScrolling through the history with the up and down arrows\nSearching the history with Ctrl+r (reverse-i-search)\nRe-running a previously run command with ! followed by the number of the command\n\n\n\n Challenge:\n\nWhat are the possible completions of ‘bed’ on the server?\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nAdd the command prompt type bed then press Tab twice. You should see the following:\n\n[USERNAME]@aabn:~$ bed<Tab><Tab>\nbed12ToBed6  bedpeToBam   bedToBam     bedToIgv     bedtools\n[USERNAME]@aabn:~$\n\n\n\n\n\n\n\n Challenge:\n\nUse the history to re-run the date -d '25 Dec' +%j command without re-typing it\n\n\nSolution\n\n\nSolution. \n\n Solution:\n\nThere are three ways to do this: One way would be to press Ctrl+r, then type date, then press Ctrl+r again repeatedly until you see the command, then press Enter to run it.\nAlternatively, you could run the history command and look back through the history list to find the command. Then you could type !at the command prompt followed by the number of the command in the history.\nA third way would be to either hit the up arrow to scroll back through the history until you see the command, then press Enter to run it."
  }
]